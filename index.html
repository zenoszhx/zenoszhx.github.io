<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>ArrayStars</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="ArrayStars">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="ArrayStars">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ArrayStars">
  
    <link rel="alternate" href="/atom.xml" title="ArrayStars" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ArrayStars</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一些个人的总结，辩证来看，不保证完全正确。</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Cocos-C++-P/3.2 精灵" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/3.2 精灵/" class="article-date">
  <time datetime="2018-11-24T03:55:32.974Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cocos2d与OpenGL-ES/">Cocos2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/3.2 精灵/">3.2 精灵</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>精灵是2D游戏中最重要的元素，它可以用来表示游戏中的元素，如树、英雄、敌人、血条、背景。游戏场景中大部分可见的元素都直接或者间接的与之有关系。</p>
<p>Cocos2d-x中用Sprite表示精灵，它将一张纹理或者纹理的一部分矩形区域绘制在屏幕上，我们可以使用精灵来减少OpenGL ES的绘制次数，可以用Sprite来播放动画，也可以设置Sprite的颜色、与场景中其他元素的混合模式。另外一些复杂的元素，如地图、粒子系统、字体等，则是基于Sprite构建的。</p>
<h3 id="1-使用Sprite绘制一个矩形区域"><a href="#1-使用Sprite绘制一个矩形区域" class="headerlink" title="1 使用Sprite绘制一个矩形区域"></a>1 使用Sprite绘制一个矩形区域</h3><p>Sprite实现了TextueProtocol接口，它可以关联一张纹理。Sprite与纹理的关系如图：</p>
<p>通过指定一张纹理及该纹理上的一个区域，就可以创建一个Sprite对象。Sprite类定义了几个重载方法以更方便地创建Sprite对象，示例如下：</p>
<pre><code>class CC_DLL Sprite : public Node, public TextureProtocol
{
public:
    static Sprite* create();

    // 直接通过文件创建
    static Sprite* create(const std::string&amp; filename);
    static Sprite* create(const std::string&amp; filename, const Rect&amp; rect);

    // 通过纹理创建
    static Sprite* createWithTexture(Textuer2D *texture);
    static Sprite* createWithTexture(Texture2D *texture, const Rect&amp; rect, bool rotated = false);

    // 通过精灵帧缓冲创建
    static Sprite* createWithSpriteFrame(SpriteFrame *pSpriteFrame);
    static Sprite* cteateWithSpriteFrameName(const std::string&amp; spriteFrameName);

static:
    BlendFunc        _blendFunc;
    Texture2D*       _texture;
    QuadCommand      _quadCommand;
    Rect             _rect;
    V3F_C4B_T2F_Quad _quad;
}
</code></pre><ul>
<li>这些方法本质上是使Sprite关联一个Texture2D对象和其上的一个区域。</li>
<li>除了createWithTexture()方法，其他创建方法都会将texture2D对象缓存在TextureCache中，因此我们应该小心处理那些手动创建的Texture2D对象，以便高效地管理内存。</li>
</ul>
<p>我们可以使用setTexture()方法来动态修改Sprite关联的纹理，从而实现精灵动画。当然我们也可以使用SpriteFrame来高效地播放精灵动画。Sprite会保持对其关联的Texture2D对你的引用计数，setTexture()方法对新的texture执行retain()操作，增加其引用计数。</p>
<h5 id="1-1-V3F-C4B-T2F-Quad结构体"><a href="#1-1-V3F-C4B-T2F-Quad结构体" class="headerlink" title="1.1 V3F_C4B_T2F_Quad结构体"></a>1.1 V3F_C4B_T2F_Quad结构体</h5><p>所有对Sprite绘制属性的修改（混合模式除外）最终都表现为对一个V3F_C4B_Quad结构体类型变量quad的修改，其定义如下：</p>
<pre><code>struct V3F_C4B_T2F_Quad
{
    // top left
    V3F_C4B_T2F t1;

    // bottom left
    V3F_C4B_T2F b1;

    // top right
    V3F_C4B_T2F tr;

    // bottom right
    V3F_C4B_T2F br;
}
</code></pre><p>V3F_C4B_T2F_Quad用来记录一个矩形图元的4个顶点的顶点属性（坐标、颜色、纹理坐标）。由于OpenGL ES不支持多边形图元，一个Quad图元实际上会被分成（t1, b1, tr）和（br, tr, b1）两个三角形图元。如下图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0917.JPG" alt=""></p>
<p>这些信息几乎（混合除外）可以表达一个基本的四边形图元的与绘制相关的特征，如移动、缩放、旋转、扭曲、颜色叠加等，我们只需要修改每个顶点的相关数据就可以。</p>
<h5 id="1-2-使用QuadCommand进行绘制"><a href="#1-2-使用QuadCommand进行绘制" class="headerlink" title="1.2 使用QuadCommand进行绘制"></a>1.2 使用QuadCommand进行绘制</h5><p>使用QuadCommand进行绘制，由于每个Sprite生成一个Quad，因此它可以和相邻的QuadCommand形成自动批绘制，示例如下：</p>
<pre><code>void Sprite::draw(Renderer *renderer, const Mat4 &amp;transform, bool transformUpdated)
{
    // Done not do calculate the culling if the transfrom was not update
    _insideBounds = transformUpdated?renderer-&gt;checkVisibility(transform, _contentSize) : _insideBounds;

    if（_insideBounds）
    {
        _quadCommand.init(_globalZorder, _texture-&gt;getName(), getGLProgramState(), _blendFunc, &amp;_quad, 1, transform);
        renderer-&gt;addCommand(&amp;_quadCommand);
    }
}
</code></pre><p>每一帧draw()方法被调用的时候，Sprite都会通过Render提供的checkVisiblity()方法来判断其自身是否处于视窗可见范围之内。如果它不可见，则不会发送任何绘制命令到OpenGL ES。这不仅减少了GPU计算的浪费，也减少了Render对RenderCommand进行排序的时间。当场景中有大量元素处于不可见状态时，如果场景中有大量元素处于不可见状态时，这样做会对性能有显著的提升。</p>
<h5 id="1-3-将Sprite作为子元素"><a href="#1-3-将Sprite作为子元素" class="headerlink" title="1.3 将Sprite作为子元素"></a>1.3 将Sprite作为子元素</h5><p>此外，Sprite提供了一种创建和修改一个四边形图元的方式，一些更复杂的且由四边形图元组成的元素，如粒子系统中的每个粒子、一段文字中的每个字符、一帧地图中的每个瓷片等，可以使用Sprite来表示。使用特定的方式来一次绘制所有四边形图元可以提高性能。这样做保持了对这些复杂元素的每个子元素属性修改的灵活性和能力，只需要提供对每个元素的索引。例如我们可以单独修改一段文字中某个字符的位置、颜色、旋转、绽放等。</p>
<h3 id="2-Sprite的绘制属性"><a href="#2-Sprite的绘制属性" class="headerlink" title="2 Sprite的绘制属性"></a>2 Sprite的绘制属性</h3><p>除了通过修改纹理和设置不同的纹理区域使Sprite显示不同的内容，我们还可以通过下面两个方面来影响OpenGL ES的绘制结果：</p>
<ul>
<li>颜色混合，用来指定当前Sprite与颜色缓冲区中相同位置颜色值的混合方式；</li>
<li>颜色叠加，将一个颜色值作用在一个图层或者精灵上</li>
</ul>
<h5 id="2-1-颜色混合"><a href="#2-1-颜色混合" class="headerlink" title="2.1 颜色混合"></a>2.1 颜色混合</h5><p>混合发生在OpenGL ES绘图管线的最后一个阶段——每个片元的处理。在这个阶段，会根据一些参数设置和条件对每个片元执行一系列的测试，其中包括像素所有权测试、裁剪测试。模板测试、深度测试、混合等，最后将颜色值输送到缓冲区，显示在屏幕上。我们可以通过glEnable和glDisable来开启各禁用混合操作。</p>
<p>（1）源、目标、缓冲区</p>
<ul>
<li>缓冲区，OpenGL ES首先将全部内容绘制到后端（back）缓冲区上，然后通过交换前端（front）和后端缓冲区将每一帧的内容输出到屏幕上。每一次绘制，绘图管线的终点都是将每个片段的颜色值写入缓冲区中存储该位置的颜色值的部分；</li>
<li>源，在片段操作阶段，光栅化产生的片段的颜色值称为源；</li>
<li>目标，缓冲区上对应该位置的的颜色值称为目标；</li>
</ul>
<p>混合模式就是将源上的R、G、B、A通道的值与目标上的R、G、B、A通道的值按一定的公式进行混合计算。</p>
<p>（2）混合计算</p>
<p>源和目标颜色的混合结果主要取决于两个方面——混合计算方程（Blend Equation）和混合模式（Blend Functions）。混合计算方程定义了源和目标中对应的通道值按怎样的公式进行计算，它分别从源和目标对应的通道取值进行计算，每个通道取值的权重则由混合模式来定义。通过以下命令来定义混合计算方程：</p>
<pre><code>void BlendEquation(enum mode);
void BlendEquationSeparate(enum modeRGB, enum modeAlpha);
</code></pre><p>其中，BlendEquationSeparate可以分别指定RGB和Alpha通道的计算方程，而BlendEquation同时指定两者。modeRGB和modeAlpha的值必须以下值之一：</p>
<ul>
<li>FUNC_ADD</li>
<li>FUNC_SUBTRACT</li>
<li>FUNC_REVERSE_SUBTRACT</li>
</ul>
<p>以上3个云计算公式分别如下表：</p>
<table>
<thead>
<tr>
<th>公式名称</th>
<th>RGB通道</th>
<th>Alpha通道 </th>
</tr>
</thead>
<tbody>
<tr>
<td>FUNC_ADD</td>
<td>R = Rs <em> Sr + Rd </em> Dr <br> G = Gs <em> Sg + Gd </em> Dg <br> B = Bs <em> Sb + Bd </em> Db</td>
<td>A = As <em> Sa + Ad </em> Da</td>
</tr>
<tr>
<td>FUNC_SUBTRACT</td>
<td>R = Rs <em> Sr - Rd </em> Dr <br> G = Gs <em> Sg - Gd </em> Dg <br> B = Bs <em> Sb - Bd </em> Db</td>
<td>A = As <em> Sa - Ad </em> Da</td>
</tr>
<tr>
<td>FUNC_REVERSE_SUBTRACT</td>
<td>R = Rs <em> Dr - Rd </em> Sr <br> G = Gs <em> Dg - Gd </em> Sg <br> B = Bs <em> Db - Bd </em> Sb</td>
<td>A = As <em> Da + Ad </em> Sa</td>
</tr>
</tbody>
</table>
<p>目标中，r下标表示源上的各个通道值，d下标表示目标上的各个通道值；变量S和D分别表示源和目标中该通道的取值权重系数，其通道由下标决定。</p>
<p>而权重系数由混合模式定义，示例如下：</p>
<pre><code>void BlendFuncSeparate(enum srcRGB, enum dstRGB, enum srcAlpha, enum dstAlpha);
void BlendFunc(enum src, enum dst);
</code></pre><p>同样，BlendFuncSeparate可以分别指定源和目标上RGB和Alpha通道的权重系数，而BlendFunc同时指定源和目标上RGBA通道的计算权重系数，所有混合模式如下表：</p>
<table>
<thead>
<tr>
<th>混合模式</th>
<th>RGB混合权重系数 <br> (Sr, Sg, Sb)或(Dr, Dg, Db)</th>
<th>Alpha混合权重系数Sa或Da</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZERO</td>
<td>(0, 0, 0)</td>
<td>0</td>
</tr>
<tr>
<td>ONE</td>
<td>(1, 1, 1)</td>
<td>1</td>
</tr>
<tr>
<td>SCR_COLOR</td>
<td>(Rs, Gs, Bs)</td>
<td>As</td>
</tr>
<tr>
<td>ONE_MINUS_SRC_COLOR</td>
<td>(1, 1, 1) - (Rs, Gs, Bs)</td>
<td>1 - As</td>
</tr>
<tr>
<td>DST_COLOR</td>
<td>(Rd, Gd, Bd)</td>
<td>Ad</td>
</tr>
<tr>
<td>ONE_MINUS_DST_COLOR</td>
<td>(1, 1, 1) - (Rd, Gd, Bd)</td>
<td>1 - Ad</td>
</tr>
<tr>
<td>SRC_ALPHA</td>
<td>(As, As, As)</td>
<td>As</td>
</tr>
<tr>
<td>ONE_MINUS_SRC_ALPHA</td>
<td>(1, 1, 1) - (As, As, As)</td>
<td>1 - As</td>
</tr>
<tr>
<td>DST_ALPHA</td>
<td>(Ad, Ad, Ad)</td>
<td>Ad</td>
</tr>
<tr>
<td>ONE_MUNUS_DST_ALPHA</td>
<td>(1, 1, 1) - (Ad, Ad, Ad)</td>
<td>1 - Ad</td>
</tr>
<tr>
<td>CUNSTANT_COLOR</td>
<td>(Rc, Gc, Bc)</td>
<td>Ac</td>
</tr>
<tr>
<td>ONE_MINUS_CUNSTANT_COLOR</td>
<td>(1, 1, 1) - (Rc, Gc, Bc)</td>
<td>1 - Ac</td>
</tr>
<tr>
<td>CONSTANT_ALPHA</td>
<td>(Ac, Ac, Ac)</td>
<td>Ac</td>
</tr>
<tr>
<td>ONE_MINUS_CUSTANT_ALPHA</td>
<td>(1, 1, 1) - (Ac, Ac, Ac)</td>
<td>1 - Ac</td>
</tr>
<tr>
<td>SRC_ALPHA_SATURATE</td>
<td>(f, f, f)²</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>通过BlendEquation和BlendFunc，就可以告知OpenGL绘图管线应该怎样将片段和缓冲区上的颜色进行混合。</p>
<ul>
<li>默认情况下，GL_FUNC_ADD是BlendEquation的默认值，它通常用来实现反锯齿、绘制半透明纹理及其他一些效果；</li>
<li>Cocos2d-x中，Sprite的_blendFunc默认设置为{GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA}，它表示目标的计算权重系数等于（1,1,1,1）- (Rs,Gs,Bs,As)，这样就可以实现对半透明图片的处理。</li>
</ul>
<p>当然，也可以利用BlendEquation和BlendFunc的组合实现更多的混合效果，示例如下：</p>
<pre><code>void Sprite::updateBlendFunc(void)
{
    if (!_texture || ! _texture-&gt;hasPremultipliedAlpha())
    {
        _blendFunc = BlendFunc::ALPHA_NON_PREMULTIPLIED;
        setOpacityModifyRGB(false);
    } else {
        _blendFunc = BlendFunc::ALPHA_PERMULTIPLIED;
        setOpacityModifyRGB(true);
    }
}
</code></pre><p>（3）混合与深度测试</p>
<p>深度测试发生于混合之前。如果场景中全是非透明图元，则它们严格按照深度测试选择颜色值即可，处于较远的图元将始终被丢弃，应用程序不会理会其绘制顺序；</p>
<p>当非透明的图元和透明的图元共同出现在同一场景时，我们应该小心地处理其绘制顺序。在这种情况下，应该先绘制非透明的图元，再按深度从后到前绘制半透明图元。如果不按这样的顺序绘制，则处半透明图元后面的非透明图元可能会被完全遮挡，这里离场景较远的非透明图元将被深度测试完全丢弃。</p>
<p>在Cocos2d-x中，Render使用globalOrder对RenderCommand进行排序，而globalOrder通常来自元素的globalZorder，从而保证RenderCommand始终按正确的顺序进行绘制，示例如下：</p>
<pre><code>bool compareRenderCommand(RenderCommand* a, RenderCommand* b)
{
    return a-&gt;getGlobalOrder() &lt; b-&gt;getGloabalOrder();
}
</code></pre><h5 id="2-2-颜色叠加"><a href="#2-2-颜色叠加" class="headerlink" title="2.2 颜色叠加"></a>2.2 颜色叠加</h5><p>混合模式通过Alpha通道计算一个图层与环境图片的组合方式，而叠加将一个颜色值作用在一个图层自身的每个颜色值通道中。这通常用来实现一些特殊的效果，如角色受到攻击之后身体闪动红色的动画效果（可以通过对精灵设置一个渐变的叠加颜色实现）。</p>
<p>在Cocos2d-x中，可以对一个Node设置颜色叠加，Node可以将这些叠加效果沿着UI树逐个向下作用在每个元素上，最终作用在Sprite或者其他可见的UI元素上。</p>
<p>（1）Node颜色叠加</p>
<p>Node实现了对一个图层进行递归颜色叠加的结构，每个子元素则将父元素传递下来的颜色叠加到对应的内容上，如Sprite将颜色叠加到纹理上。与Node基类颜色叠加的方法如下：</p>
<pre><code>class CC_DLL Node : public Ref
{
public:
    virtual GLubyte getOpactity() const;
    virtual GLubyte getDisplayedOpacity() const;
    virtual void setOpacity(GLutyte opacity);
    virtual void updateDisplayedOpactiy(GLubyete paremtOpacity);
    virtual bool isCascadeOpatityEnabled() const;
    virtual void setCascadeOpacityEnabled(bool cascadeOpacityEnabled);

    virtual const Color3B&amp; getColor(void) const;
    virtual const Color3B&amp; getDisplayedColor() const;
    virtual void setColor(const Color3B&amp; color);
    virtual void updateDisplayedColor(const Color3B&amp; parentColor);
    virtual bool isCascadeColorEnabled() const;
    virtual void setCascadeColorEnabled(bool cascadeColorEnabled);

    virtual void setOpacityModifyRGB(bool bValue){CC_UNUSED_PARAM(bValue);}
    virtual bool isOpacityModifyRGB() const {return false};
}
</code></pre><ul>
<li>cascade相关方法用来表示是将颜色叠加至当前元素，还是将颜色叠加向下传递；</li>
<li>注意，在一些情况下不能使用颜色叠加；</li>
<li>realColor()方法和realOpacity()方法记录元素本身的颜色属性，displayedColor()和displayedOpacity()方法则用于表示与父元素叠加过后最终的绘制颜色。</li>
</ul>
<p>叠加公式使用每个对应通道的值相乘，如下：（其中，parentColor取自父元素的displayColor）</p>
<pre><code>void Node::updateDisplayedColor(const Color3B&amp; parentColor)
{
    _displayedColor.r = _realColor.r * parentColor.r/255.0;
    _displayedColor.g = _realColor.g * parentColor.g/255.0;
    _displayedColor.b = _realColor.b * parentColor.b/255.0;
    updateColor();

    if (_cascadeColorEnabled)
    {
        for(const auto &amp;child : _childern)
        {
            child-&gt;updateDisplayedColor(_displayedColor);
        }
    }
}
</code></pre><p>如果设置的cascade的相关属性，则会向下传递，示例如下：</p>
<pre><code>void Node::updateDisplayedOpacity(GLubyte parentOpacity)
{
    _displayedOpacity = _realOpacity * parentOpacity/255.0;
    updateColor();

    if (_cascadeOpacityEnabled)
    {
        for(auto child : _children)
        {
            child-&gt;updateDisplayedOpacity(_displayedOpacity);
        }
    }
}
</code></pre><p>（2）精灵颜色叠加</p>
<p>Sprite通过片段着色器将颜色叠加作用在纹理上，并最终绘制叠加后的纹理。在对Sprite设置颜色时，Sprite的updateColor()重载方法会将叠加计算后的displayedColor的值存储到顶点数组quad中。quad的每个顶点属性中包含一个颜色值，Spriter的displayColor的默认值为Color3B::WHITE，示例如下：</p>
<pre><code>void Sprite::updateColor(void)
{
    Color4B color4(_displayedColor.r, _displayedColor.g, _displayedColor.b, _displayedOpactiy);

    if (_opacityModifyRGB)
    {
        color4.r *= _displayedOpacity/255.0f;
        color4.g *= _displayedOpacity/255.0f;
        color4.b *= _displayedOpacity/255.0f;
    }

    _quad.b1.colors = color4;
    _quad.br.colors = color4;
    _quad.t1.colors = color4;
    _quad.tr.colors = color4;
}
</code></pre><p>opacityModify属性在后面介绍，在Cocos2d-x中，Sprite默认使用SHADER_NAME_POSITION_TEXTURE_COLOR_NO_MVP着色组。顶点着色器中的顶点坐标、纹理及颜色分别使用变量a_position、a_texCoord、a_color输入，示例如下：</p>
<pre><code>ccShader_PositionTextureColor_noMVP_vert.h

attribute vec4 a_position;
attribure vec2 a_texCoord;
attribure vec4 a_color;

#ifdef GL_ES
varying lowp vec4 v_fragmentColor;
varying mediump vec2 v_texCoord;
#else
varying vec4 v_fragmentColor;
varying vec2 v_texCoord;
#endif

void main()
{
    gl_Position = CC_PMatrix * a_position;
    v_fragmentColor = a_color;
    v_texCoord = a_texCoord;
}
</code></pre><p>在片段着色器中，Sprite的displayedColor最终被叠加到每个从纹理采样的片段，从而实现了Sprite对纹理的颜色叠加，示例如下：</p>
<pre><code>ccShader_PositionTextureColor_noMVP_frag.h

#ifdef GLES
precision lowp float;
#endif

varying vec4 v_fragmentColor;
varying vec2 v_texCoord;
uniform sampler2D CC_Texture0;

void main()
{
    gl_FramColor = v_fragmentColor * texture2D(CC_Texture0, v_texCoord);
}
</code></pre><p>着色器Shader的相关知识将在后面讲述，这里texture2D(CC_Texture)就是Sprite的realColor，而v_fragmentColor就是Sprite的parentClolor，其默认值为Color3D::WHITE时不会对realColor造成任何影响。</p>
<p>通过Node的递归叠加结构和Sprite的叠加，最终可以对场景中每个元素实现颜色的叠加。对于自定义的元素，我们也需要实现颜色的叠加。在Cocos2d-x中，我们可以通过TintTo、TintBy实现颜色叠加的动画效果。</p>
<h3 id="3-Alpha预乘"><a href="#3-Alpha预乘" class="headerlink" title="3 Alpha预乘"></a>3 Alpha预乘</h3><p>如果一张图片包含Alpha通道，那么在最终组合时一般使用颜色值乘以Alpha值，然后与剩余的Alpha值乘以背景的颜色值相加。可以想像为：一个半透明的物体透过一部分光穿透到背景，Alpha用于决定有多少光可以穿透该物体。</p>
<p>Sprite的默认混合模式如下：</p>
<pre><code>BlendEquation : GL_GUNC_ADD
BlendFunc : {GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA}
</code></pre><p>最终组合结果如下：</p>
<pre><code>(Rs, Gs, Bs) * As + (Rd, Gd, Bd) * (1 - As)
</code></pre><h5 id="3-1-什么是Alpha预乘"><a href="#3-1-什么是Alpha预乘" class="headerlink" title="3.1 什么是Alpha预乘"></a>3.1 什么是Alpha预乘</h5><p>为了减少颜色组合时的计算量，提高应用程序的性能，Alpha预乘的概念被提出。它将RGB通道的值保存为自身实际的颜色乘以Alpha之后的值，这样运行时只需要计算背景部分的颜色就可以进行组合了。</p>
<p>Alpha预乘仅仅是一种思路，实际的图片存储格式（如PNG、PVR等）并不支持这种技术。如果使用了non-permultiplied和permultiplied同一张png图片，实际上对于png来说是两种不同颜色值的图片，在效果上相当于将原图与一张黑色(0, 0, 0, 1)的背景组合。</p>
<p>因此，Alpha预乘技术需要通过程序的支持实现，通常需要设置混合模式。</p>
<h5 id="3-1-Alpha预乘在Cocos2d-x中的应用"><a href="#3-1-Alpha预乘在Cocos2d-x中的应用" class="headerlink" title="3.1 Alpha预乘在Cocos2d-x中的应用"></a>3.1 Alpha预乘在Cocos2d-x中的应用</h5><p>Cocos2d-x中不能从图片信息中获取该图片是否使用了Alpha预乘，但Cocos2d-x提供了对Premultiplied的支持，可以从如下3个方面使用Premultiplied Alpha。</p>
<p>（1）设置Sprite的BlendFunc使用。</p>
<p>只要修改BlendFunc的设置为{GL_ONE, GL_ONE_MINUS_SRC_ALPHA}，就可以正确显示纹理，但是这要求对每一个premultiplied的纹理都进行设置；</p>
<p>（2）构造Image时告知</p>
<p>构造Image时告知其已经使用Premultiplied过Alpha了，可以看到preMulti参数默认是false，但是开发者通常不会下拉创建Image对象。示例如下：</p>
<pre><code>class CC_DLL Image : plublic Ref
{
public:
    bool initWithRawData(const unsigned char * data, ssize_t dataLen, int width, int height, int bitsPerComponent, bool preMulti = false);
}
</code></pre><p>（3）使用Texture2D提供的静态方法，这只针对PVR格式的纹理</p>
<pre><code>static void PVRImagesHavePremultipliedAlpha(bool haveAlphaPremultiplied);    
</code></pre><p>如果所有的纹理都是Premultiplied，则可以在configure中设置对所有PVR纹理使用Premultiplied，示例如下：</p>
<pre><code>void Director::setDefaultValues(void)
{
    Configuration *conf = Configuration::getInstance();

    bool prv_alpha_premultiplied = conf-&gt;getValue(&quot;cocos2d.x.texture.pvrv2_has_alpha_premultiplied&quot;, Value(false)).asBool();
    Texture2D::PVRImageHavePremultipliedAlpha(pvr_alpha_premultiplied);
}
</code></pre><p>这样，Sprite在使用premultiplied的纹理时，updateBlendFunc()方法将自动使用ALPHA_PREMULTIPLIED进行混合设置，示例如下：</p>
<pre><code>void Sprite::updateBlendFunc(void)
{
    if (!_texture || !_texture-&gt;hasPremultipliedAlpha)
    {
        _blendFunc = BlendFunc::ALPHA_NON_PREMULTIPLIED;
        setOpacityModifyRGB(false);
    } else {
        bledFunc = BlendFunc::ALPHA_PREMULTIPLIED;
        setOpacityModifyRGB(true);
    }
}
</code></pre><p>使用Premultiplied也有一些缺点，如预乘减少了颜色值的精度。如果我们在Shader或者其他场景中需要将颜色值还原，严重情况下会造成比较明显的质量损失。</p>
<h3 id="4-精灵表和精灵动画"><a href="#4-精灵表和精灵动画" class="headerlink" title="4 精灵表和精灵动画"></a>4 精灵表和精灵动画</h3><p>精灵表将多个精灵合并在一幅图上，并通过一个配置文件（XML、JSON、PLOST）表示纹理的尺寸，这样可以减少OpenGL ES的绘制次数。精灵表可以用于将场景中独立的精灵合并在一张纹理上，也可以用于存储一系列关键帧动画，还可以表示骷髅动画的各个关节。</p>
<h5 id="4-1-精灵表"><a href="#4-1-精灵表" class="headerlink" title="4.1 精灵表"></a>4.1 精灵表</h5><p>Cocos2d-x使用SpriteFrameCache加载精灵表及缓存每一个精灵信息，它通过解析配置文件将精灵表中的每个精灵存储为一个SpriteFrame对象。每个SpriteFrame包含该精灵的纹理、尺寸、在纹理中的位置信息，可以通过一个SpriteFrame创建一个Sprite。SpriteFrame定义如下：</p>
<pre><code>class CC_DLL SpriteFrame : public Ref, public Clonable
{
protected:
    Point _offset;
    Size _originalSize;
    Rect _rectInPixels;
    bool _rotated;
    Rect _rect;
    Point _offsetInPixels;
    Size _originalSizeInPixels;
    Texture2D *_texture;
    std::string _textureFilename;
}
</code></pre><p>与TextureCache类似，SpriteFrameCache提供对SpriteFrame的共享各缓存，如下图所示：</p>
<p>预先加载精灵表后，通过每个精灵在配置表中的名称就可以获取一个SpriteFrame，同样，SpriteFrameCache也可以移除那些末使用的SpriteFrame对象。</p>
<p>值得注意的是，SpriteFrameCache并不提供移除对应于Texture2D对象的功能。因为一个Texture2D对象可能被其他非SpriteFrame对象引用，所以，如果我们确定一个精灵表不再使用，还应该移动对应的Texture2D对象。</p>
<h5 id="4-2-精灵动画"><a href="#4-2-精灵动画" class="headerlink" title="4.2 精灵动画"></a>4.2 精灵动画</h5><p>（1）关键帧动画与骨骼动画</p>
<p>在2D游戏中，精灵动画分为关键帧动画各骨骼动画。关键帧动画在每一个关键帧间隔内显示一系列动画图像的一张；骨骼动画对身体各个部件在关键帧之间进行插值。</p>
<p>关键帧动画通常占据更多的存储空间，但是二者都有自己的特长，关键帧擅长变化比较丰富的特效，骨骼擅长处理人物动作等局部变化。</p>
<p>（2）使用</p>
<p>不管是关键帧动画还是骨骼动画，它们都需要多个精灵，因此精灵表是精灵动画的基础，当然在关键帧中也可以使用单个的精灵来切换，但是使用精灵表会方便更多。如下图所示，关键帧动画各骷髅动画中所引用的精灵均取自SpriteFrameCache中的SpriteFrame，这样可以把重心放在动画的使用上，而不是处理每个精灵的细节上：</p>
<p>每个精灵帧动画都是由一个或多个动画组成的，每个精灵动画都有一个配置文件来存储这些动画中相应的动画信息。例如，关键帧动画的配置文件要存储每一帧使用的精灵名称及帧率，而骨骼动画的配置文件要存储每个关节对应的精灵名称及每个关键帧、每个骨骼的变化信息。</p>
<p>一个关键帧的动画配置如下图所示：</p>
<p>该动画由一个名为dance_1的动画构成，dance_1关键帧之间的间隔是0.2秒，由14个关键帧构成，这些关键帧所对应的精灵取自grossini.plist、grossini_blue.plist、grossini_family.plist这3个精灵表。在应用程序中，我们只需要从AnimationCache中获取名为dance_1的Animation即可。</p>
<p>骨骼动画与精灵动画类似，只不过它的每个动画内存储的是骨骼的变化信息。精灵动画各骨骼动画通过精灵表的定义，使用由设计师导出的配置文件定义这些复杂的动画设计，简化了程序中动画的使用。</p>
<h3 id="5-批绘制还是自动批绘制"><a href="#5-批绘制还是自动批绘制" class="headerlink" title="5 批绘制还是自动批绘制"></a>5 批绘制还是自动批绘制</h3><p>Cocos2d-x 3.x中加入了自动批绘制，这得益于新增的绘制栈的实现。自动批绘制需要满足下面4个条件：</p>
<ul>
<li>使用同一张纹理</li>
<li>相同的BlendFunc设置</li>
<li>相同的Shader程序</li>
<li>在绘制顺序上相邻</li>
</ul>
<p>这使得我们不必关心批绘制的细节，只需要遵循一定的规则就可以提高应用程序的渲染性能。</p>
<p>在Cocos2d-x 2.x中，使用SpriteBatchNode支持批绘制，到目前版本，我们仍然可以在程序中使用SpriteBatchNode，并且仍然在Label、TileMap、ParticleSystem中使用SpriteBatchNode或者类似的原理进行批绘制。下面将具体介绍这种技术。</p>
<h5 id="5-1-SpriteBatchNode"><a href="#5-1-SpriteBatchNode" class="headerlink" title="5.1 SpriteBatchNode"></a>5.1 SpriteBatchNode</h5><p>SpriteBatchNode继承自Node，并实现了TextureProtocol接口，重写了Node的addChild、visit、draw方法。</p>
<p>addChild方法限制了其子元素只能是Sprite，并且了元素与SpriteNode必须使用同一个Texture2D对象，示例如下：</p>
<pre><code>void SpriteBatchNode::addChild(Node *child, int zOrder, int tag)
{
    CCASSERT(child != nullprt, &quot;child should not be null&quot;);
    CCASSERT(dynamic_cast&lt;Sprite*&gt;(child) != nullptr, &quot;CCSpriteBatchNode only supports Sprites as children&quot;);

    Sprite *sprite = static_case&lt;Sprite*&gt; (child);

    CCASSERT(sprite-&gt;getTexture()-&gt;getName() == _textureAtlas-&gt;getTexture()-&gt;getName(), &quot;CCSprite is not using the same texture id&quot;);

    Node::addChild(child, zOrder, tag);
    appendChild(sprite);
}
</code></pre><p>visit方法用于阻止元素向下遍历，将所有子元素的绘制工作交给自己处理，示例如下：</p>
<pre><code>void SpriteBatchNode::visit(Render *renderer, const kmMatt4 &amp;parentTransform, bool parentTransformUpdate)
{
    if (!_visible){
        return;
    }

    sortAllChildren();

    bool dirty = parentTransformUpdated || _transformUpdated;
    if (dirty)
        _modelViewTransform = transform(parentTransform);
    _transformUpdated = false;

    kmGLPushMatrix();
    kmGLLoadMatrix(&amp;_modelViewTransform);
}
</code></pre><p>draw方法使用BatchNodeCommand将绘制命令发送到RenderQueue，从而对所有的子元素进行绘制。示例如下：</p>
<pre><code>void SpriteBatchNode::draw(Renderer *renderer, const kmMat4 &amp;transform, bool transformUpdated)
{
    if (_textureAtlas-&gt;getTotalQuads() == 0)
    {
        return;
    }

    for (const suto &amp;child : _children)
        child-&gt;updateTransform();

    _batchCommand.init(_globalZOrder, _shaderProgram, blendFunc, _textureAlas, transform);

    renderer-&gt;addCommand(&amp;_batcgCommand);
}
</code></pre><p>Sprite被添加到SpriteBatchNode元素中，所有Sprite和SpriteBatchNode使用同一张纹理，SpriteBatchNode向Renderer发送BatchCommand的命令进行绘制，Sprite只提供一个四边形图元。</p>
<h5 id="5-2-TextureAtlas"><a href="#5-2-TextureAtlas" class="headerlink" title="5.2 TextureAtlas"></a>5.2 TextureAtlas</h5><p>SpriteBatchNode使用TextureAtlas存储所有子精灵的顶点信息。TextureAtlas包含一个V3F_C4B_T2F_Quad数组和一个Texture2D对象，提供对quads数组的添加、删除、修改和排序等功能。示例如下：</p>
<pre><code>class CC_DLL TextureAtlas : public Ref
{
    void updateQuad(V3F_C4B_T2F_Quad* quad, ssize_t index);
    void insertQuads(V3F_C4B_T2F_QUad* quads, ssize_t index, ssize_t amount);
    void insertQuadFromIndex(ssize_t fromIndex, ssize_t newIndex);
    void removeQuadAtIndex(ssize_t index, ssize_t amount);
    void removeallQuqds();
    bool resizeCapacity(ssize_t capacity);
    void moveQuadsFromIndex(ssize_t oldIndex, ssize_t amount, ssize_t newIndex);
    void drawNumberOfQuads(ssize_t numberOfQuads, ssize_t start);
    void drawQuads();
    ssize_t getTotalQuads() const;
    ssize_t getCapcity() const;
    Texture2D* getTexture() const;
    void setTexture(Texture2D* texture);
    V3F_C4B_T2F_Quad* getQuads();
    void setQuads(V3F_C4B_T2F_Quad* quads);
}
</code></pre><p>这样SpriteBatchNode所做和事情主要就是将与子元素相关的顶点信息存储至TextureAtlas中。最后，TextureAtlas提供了绘制quads的方法，BatchCommand就是通过drawQuads()方法绘制的，示例如下：</p>
<pre><code>void BatchCommand:execute()
{
    _shader-&gt;use()
    _shader-&gt;setUniformsForBuiltins(_mv);
    GL::blendTexture2D(_textureID);
    GL::blendFunc(_blendType.drc, _blendType.dst);

    _textureAtlas-&gt;drawQuads();
}
</code></pre><p>除此之外，Cocos2d-x中的Label、TileMap、ParticleSystem等元素也是通过TextureAtlas进行绘制的。</p>
<h5 id="5-3-SpriteBatchNode的特点和限制"><a href="#5-3-SpriteBatchNode的特点和限制" class="headerlink" title="5.3 SpriteBatchNode的特点和限制"></a>5.3 SpriteBatchNode的特点和限制</h5><p>由于SpriteBatchNode只执行一次绘制，所以不能为每个Sprite单独设置相关的OpenGL ES绘制参数，如反锯齿、过滤模式、拉伸模式、混合模式等，且只能使用一个着色程序。这些Sprite的层级都是相邻的，它不能在其他层级的元素之间混合使用。</p>
<p>此外，将场景中多个Sprite置于一个SpriteBatchNode之下，不仅管理不方便，场景中也可能包含非Sprite的元素，同时，这要求开发者时刻记住每个元素使用的纹理。</p>
<p>SpriteBatchNode适合那些比较简单的模型，它们的子元素只能来自同一个纹理，这些子元素也都位于同一相邻层级，甚至不会重叠。在这些模型中，Label、TileMap、ParticleSystem都非常符合这些特征。而其他情况下，应用程序中使用的精灵都应该使用Sprite的自动批绘制。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/3.2 精灵/" data-id="cjov31ri3000w88riayn1ck6l" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/3.1（2） 纹理压缩及应用" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/3.1（2） 纹理压缩及应用/" class="article-date">
  <time datetime="2018-11-24T03:55:32.969Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cocos2d与OpenGL-ES/">Cocos2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/3.1（2） 纹理压缩及应用/">3.1(2) 纹理压缩及应用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="8-纹理压缩"><a href="#8-纹理压缩" class="headerlink" title="8 纹理压缩"></a>8 纹理压缩</h3><p>纹理占据了大量的存储空间和游戏内存，传统的压缩方案（如jpg）能够减少资源的大小，但无法对内存有较大的贡献。</p>
<p>一个图形数据在被传输到OpenGL ES服务端内存时，由于OpenGL ES并不识别一般的压缩算法，所以这些数据需要被转化为RGB或者RGBA等未压缩格式才能保证实时渲染性能，因此需要一种针对GPU的纹理压缩方案，使GPU可以直接从压缩纹理中采样并进行渲染。由于纹理在内存中以压缩的格式存在，所以此方法不仅能减少资源的大小，还能减少内存的占用。</p>
<h5 id="8-1-压缩纹理的特点"><a href="#8-1-压缩纹理的特点" class="headerlink" title="8.1 压缩纹理的特点"></a>8.1 压缩纹理的特点</h5><p>纹理压缩技术，相较于其他图像压缩技术具有以下四个方面特征：</p>
<ul>
<li>解压速度：为了使渲染系统可以直接从压缩纹理中读取数据，该压缩技术必须具有较快的解压速度，才能避免影响渲染系统的性能。传统压缩技术主要针对存储或者文件传输进行设计，不具备较快的解压速度。</li>
<li>随机读取：由于纹理中的任何位置都可能被图元映射，因此，片段可能会随机读取纹理中任何位置的纹素，这就要求压缩技术必须被随机读取。传统的压缩技术使用可变的压缩压缩比例，读取某个像素的信息可能要解压很大一部分相关的像素信息。压缩纹理技术则使用固定的压缩比例，访问像素时可以根据索引快速读取某一小块的内容，从而高效地实现随机读取。</li>
<li>压缩率和图像质量：传统图像压缩技术，大多要考虑图像的质量（这些压缩图自身会作为一个整体被查看和使用）。对于纹理压缩格式，每个纹理只是场景一部分，整体场景渲染的质量高于单个图片，所以压缩纹理通常使用有损压缩。</li>
<li>编码速度：压缩纹理的压缩过程通常发生在应用程序之外，因此不需要较高的编码速度。使用压缩纹理的核心制约因素是解压速度。</li>
</ul>
<p>满足上述特点的纹理压缩方法不仅可以减少图像资源的大小，还可以配合GPU进行高效渲染，从而减少内存的占用，同时减少了应用程序客户端向GL服务端传输纹理数据的带宽</p>
<p>由于压缩纹理减小了内存占用和其直接存储在GPU中，芯片可以对其进行更高效的使用，从而减少移动设备的耗电量。另外，在OpenGL ES中，压缩纹理与其他纹理一样进行采样，支持多级纹理，应用程度除了通过特殊的glCompressedTexImage2D传输纹理，其他方面和普通纹理几乎无区别。</p>
<h5 id="8-2-压缩纹理的实现"><a href="#8-2-压缩纹理的实现" class="headerlink" title="8.2 压缩纹理的实现"></a>8.2 压缩纹理的实现</h5><p>压缩纹理的算法超出当前范畴，这是只解释随机读取的大概思路。</p>
<p>传统图像压缩算法都是为了存储、传输等目的而设计的，不是为了进行实时渲染。为了保证最大的压缩比率，使用了一个可变的压缩比率，导致解压时要解压更多的像素位才能读取某个像素的位置，这对于随机和快速读取都是不利的。</p>
<p>压缩纹理使用一个固定的压缩比率，它首先按照这个比率将纹理分成像素块，每个像素块包含如2×2、4×4个像素，每个被压缩的像素信息存储在一个像素集合中（Codebook），一个块索引图（Index Map）存储了每个每个像素块的索引位置。在读取时，首先根据块索引找到像素块，然后解压该像素块，读取偏移值的信息，称为基于块的压缩算法。如图：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911%E5%8E%8B%E7%BC%A9%E7%BA%B9%E7%90%86%E8%AF%BB%E5%8F%96.jpg" alt=""></p>
<p>上图所示的像素读取过程如下：</p>
<p>（1）将纹理坐标转化为块索引值，计算出块索引值，以及该坐标在像素块内的偏移值。</p>
<p>（2）根据块索引值在像素集合中（Codebook）中查找对应的像素块。</p>
<p>（3）在这一段像素块中查找纹理坐标（i, j）的颜色值。</p>
<p>通过固定数量的像素块进行压缩，压缩纹理能够更快的读取。在实际操作的时候，对于一个像素块的数据，还可以根据实际情况进行缓存。这种快速的解压使图形渲染管线可以不依赖CPU的解压就实现实时渲染。将压缩纹理直接保存在GPU内存中，即减少了磁盘的占用，也节省了内存的占用，还减少了纹理在内存中所占用的带宽。</p>
<h5 id="8-3-在Cocos2d中使用压缩纹理"><a href="#8-3-在Cocos2d中使用压缩纹理" class="headerlink" title="8.3 在Cocos2d中使用压缩纹理"></a>8.3 在Cocos2d中使用压缩纹理</h5><p>Cocos2d-x支持的纹理压缩格式参见PixelFormat枚举的定义如下：</p>
<pre><code>class CC_DLL Texture2D : public Ref
{
public:
    enum class PixelFormat
    {
        // 4-bit PVRTC-compressed texture: PVRTC4
        PVRTC4,
        // 4-bit PVRTC-compressed texture: PVRTC4(has alpha channel)
        PVRTC4A,
        // 2-bit PVRTC-compressed texture: PVRTC2
        PVRTCs2,
        // 2-bit PVRTC-compressed texture: PVRTC4(has alpha channel)
        PVRTC2A,
        // ETC-compressed texture: ETC
        ETC,
        // S3TC-compressed texture: S3TC
        S3TC,
        // S3TC-compressed texture: S3TC_DXT1
        S3TC_DXT1,
        // S3TC-compressed texture: S3TC_DXT3
        S3TC_DXT3,
        // S3TC-compressed texture: S3TC_DXT5
        S3TC_DXT5,
        // ATITC-compressed texture: ATITC_RGB
        ATC_RGB,
        // ATITC-compressed texture: ATICT_EXPLICIT_ALPHA
        ATC_ESPLICIT_ALPHA,
        // ATITC-compressed texture: ATICT_INTERPOLATED_ALPHA
        ATICT_INTERPOLATED_ALPHA,
    }
}
</code></pre><p>不同的压缩格式需要不同的GPU来支持。例如，iOS全系列产品都支持PVRTC压缩格式，几乎大部分Android设备都支持ETC压缩格式，其他一些压缩格式则需要查询具体的硬件支持信息。我们可以使用Configuration::gatherGPUInfo来查询各种压缩纹理的支持信息。</p>
<pre><code>void Configuration::getherGPUInfo()
{
    _supportsETC1 = checkForGLExtension(&quot;GL_OES_compressed_ETC1_RGB8_texture&quot;);
    _valueDict[&quot;gl.supports_ETC1&quot;] = value(_supportsETC1);

    _supportsS3TC = checkForGLExtension(&quot;GL_EXT_texture_compression_s3tc&quot;);
    _valueDict[&quot;gl.supports_S3TC&quot;] = value(_supportsS3TC);

    _supportsATITC = checkForGLExtension(&quot;GL_AMD_compressed_ATC_texture&quot;);
    _valueDict[&quot;gl.supports_ATITC&quot;] = value(_supportsATITC);

    _supportsPVRTC = checkForGLExtension(&quot;GL_IMG_compressed_pvrtc&quot;);
    _valueDict[&quot;gl.supports_PVRTC&quot;] = value(_supportsPVRTC);

    CHECK_GL_ERROR_DEBUG();
}
</code></pre><p>此外，在加载纹理的时候，Image::detectForamt会自动检测图像的格式。</p>
<h5 id="8-4-PVR和PVRTC2"><a href="#8-4-PVR和PVRTC2" class="headerlink" title="8.4 PVR和PVRTC2"></a>8.4 PVR和PVRTC2</h5><p>OpenGL ES并没有提供任何纹理压缩格式，它仅提供glCommpressTexImage2D()方法供应用程序上传压缩纹理。而压缩纹理的格式通常是由图形硬件厂商或第三方组织提供的。</p>
<p>（1）PVRTC仅支持POT纹理，PVRTC2增强了PVRTC的图像质量，同时支持NPOT纹理，更好地支持Alpha预乘。</p>
<p>（2）PVRTC和PVRTC2都支持透明的RGBA图像和非透明的RGB图像，而且，如果一个图像不包含Alpha图像，则PVRTC的所有数据将全部用于存储RGB数据，从而进一步提升压缩率和图像质量。</p>
<p>（3）此处，图像格式还可以使用Alpha预乘（Premultiplied Alpha）的技术来提升图像渲染时的性能。由于对于压缩纹理的数据直接上传至GPU，客户端不会尝试解压其中的数据，所以，客户端并不能判定一个PVRTC格式的图像是否使用了Alpha通道，而Alpha预乘需要告知客户端相关信息以进行特定的配合处理。所以Cocos2d-x增加了一个静态方法手动设置PVRTC是否使用了Alpha预乘：</p>
<pre><code>void Texture2D::PVRImagesHavePremultipliedAlpha(bool haveAlphaPremultiplied)
{
    _PVRHaveAlphaPremultiplied = haveAlphaPremultiplied;
}
</code></pre><h5 id="8-5-ETC"><a href="#8-5-ETC" class="headerlink" title="8.5 ETC"></a>8.5 ETC</h5><p>几乎所有的Android设备都支持ETC格式，ETC支持4bpp的压缩比率，但不支持Alpha通道。</p>
<p>解决ETC的Alpha通道方案都涉及将图像的Alpha通关提取出来。AMD提出供的工具Amli Texture Compression Tool能够很方便的处理Alpha通道，主要关注以下两种方式。</p>
<p>（1）Create atlas</p>
<p>Create atlas方式将Alpha通道转换为可见的灰度图像，然后串联到原始纹理上，生成的纹理高度是原始图像的2倍。</p>
<p>这样，应用程序只要在片段着色器中对纹理多做一次Alpha采样即可。在Cocos2d-x中需要实现一个自定义的着色器。</p>
<p>纹理拼图的实现比较简单，但是它增大了纹理的尺寸，对有些纹理则无法扩充到2倍。例如，有些设备支持的最大纹理尺寸为2084*2084像素，所以尺寸超过1024像素的纹理就无法使用这种方式。</p>
<p>（2）将Alpha通道单独生成一张纹理</p>
<p>如下图所示，这保持了原图尺寸，却需要使用前面讲述的多重纹理技术来将两个纹理绑定到GL中。此后，片段着色器会将原图的RGB颜色值各Alpha灰度值组合在一起。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911ETC.JPG" alt=""></p>
<h5 id="8-6-针对不同设备使用不同压缩纹理"><a href="#8-6-针对不同设备使用不同压缩纹理" class="headerlink" title="8.6 针对不同设备使用不同压缩纹理"></a>8.6 针对不同设备使用不同压缩纹理</h5><p>尽管OpenGL ES 3.0提供了压缩纹理标准，使各个平台都可以使用同一种压缩纹理格式，但目前设备还需要很长时间才能过渡到Open GL 3.0，因此，我们仍然需要对不同的设备使用不同的压缩纹理格式。</p>
<h3 id="9-纹理缓存管理"><a href="#9-纹理缓存管理" class="headerlink" title="9 纹理缓存管理"></a>9 纹理缓存管理</h3><p>纹理缓存的主要目标是如下：</p>
<p>（1）使只有当前场景需要显示的纹理驻留在内存中</p>
<p>开发者的职责是要定义哪些是当前场景需要使用我资源。</p>
<p>（2）在纹理使用期间，它应该只被创建一次，并且避免动态加载纹理。</p>
<p>我们始终应该在进入一个场景时预先加载相关的纹理，因为纹理资源通常是从磁盘读取并且需要传输到GPU内存中，这是一个耗时的过程，而且这个过程是在主线程中完成的，所以不适合在游戏进行过程中读取各加载。</p>
<h5 id="9-1-纹理的生命周期"><a href="#9-1-纹理的生命周期" class="headerlink" title="9.1 纹理的生命周期"></a>9.1 纹理的生命周期</h5><p>在Cocos2d-x中，一个Texture2D实例对应于OpenGL ES中的一张纹理。Texture2D在被创建时会从磁盘中加载数据并上传至GPU内存中，发生在initWithMipmaps()方法中，如下：</p>
<pre><code>bool initWithMipmaps(MipmapInfo* mipmaps, int mipmapNums, PixelFormat pixelFormat, int pixelsWide, int pixelHigh)
{
    glGenTextures(1, &amp;_name);
    GL::bindTexture(_name);

    if (mipmapsNum == 1)
    {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    }else{
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_NEAREST);
    }

    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);

    for (int i = 0; i &lt; mipmapNum, i++)
    {
        unsigned char *data = mipmaps[i].adress;
        GLsizei = datalen = mipmaps[i].len;

        if (info.compress)
        {
            glCompressedTexImage2D(GL_TEXTURE_2D, i, info.internalForamt, (GLsizei)width, (GLsizei)heith, 0, datalen, data);
        } else {
            glTexImage2D(GL_TEXTURE_2D, i, info.internalFormat, (GLsizei)width, (GLsizei)height, 0, info.format, info.type, data);
        }
    }
    return true;
}
</code></pre><p>在initWithMipMaps()方法中，首先创建纹理名称，并设置我们前面讲到的纹理过滤模式等，最后通过glTexImage2D()方法或者glCompressTexImage2D()方法将纹理数据上传至GPU内存中。</p>
<p>每个Texture2D实例在未被销毁之前，GPU会一直缓存该纹理对象。如果销毁Texture2D，则会删除对应的纹理对象，例如：</p>
<pre><code>Texture2D::~Texture2D()
{
    CCLOGINFO(&quot;deallocing Texture2D : %p - id = %u&quot;, this, _name);
    CC_SAFE_RELEASE(_shaderProgram);


    if(_name)
        GL::deleteTexture(_name);
}
</code></pre><p>一方面，我们需要小心处理Texture2D的生命周期，它必须在纹理不再被使用之后删除。另一方面，一个纹理可能只是暂时不被使用，这种情况下，为了避免从磁盘重新加载纹理，应该将纹理缓存起来。</p>
<p>通常我们不直接创建Texture2D对象，而是通过TextureCache来创建和销毁Texture2D对象。Texture2D提供了对Texture更好的管理方式。</p>
<h5 id="9-2-用TextureCache来管理纹理"><a href="#9-2-用TextureCache来管理纹理" class="headerlink" title="9.2 用TextureCache来管理纹理"></a>9.2 用TextureCache来管理纹理</h5><p>在Cocos2d-x中，TextureCache负责纹理的创建、缓存和删除，几乎所有的UI元素需要的纹理都是通过TextureCache创建的。TextureCache对每个Director对象只有一个实例。</p>
<pre><code>class CC_DLL TextureCache : public Ref
{
public:
    Texture2D* addImage(const std::string &amp;filePath);
    virtual void addImageAsync(const std::string &amp;filePath, std::function&lt; void(Texture2D*)&gt; callback);
    Texture2D* addImage(Image *image, const std::string &amp;key);
    Texture2D* getImageForKey(const std::string &amp;key) const;
    void removeAllTextures();
    void removeUnusedTextures();
    void removeTexture(Texture2D* texture);
    void removeTextureForKey(const std::string &amp;key);
    std::string getCacheTextureInfo() const;
}
</code></pre><p>TextureCache最重要的功能体现在下面两个地方</p>
<p>（1）为每个纹理的Texture2D对象创建一个索引键</p>
<p>后续UI使用一个已经被创建的Texture2D对象时，它直接返回该对象的指针。索引键主要分为两大类：</p>
<ul>
<li>当使用文件名创建纹理时文件所在的全路径自动成为该纹理对象的索引键；</li>
<li>手动给通过Image创建的纹理分配一个指定的索引键，这用在比如通过从从RenderTexture来创建一个纹理（RenderTexture元素引用的Texture2D对象没有放在TextureCache中，当移除RenderTexture对象时将直接删除纹理）。</li>
</ul>
<p>（2）使用addImageAsync()方法异步加载纹理</p>
<p>通常在进入一个新场景时，使用一个加载界面来预加载该场景需要使用的大多数或者所有纹理，以避免游戏进行中的动态加载，增强游戏体验。使用Cocos2d-x 2.x，会为现在指定一个图片的路径数组感到惊喜。</p>
<p>TextureCache通过自动关联纹理路径或者手动分配索引键，使一个纹理可以被多次分享，那么在TextureCache管理下的生命周期发生了什么变化？如下图：</p>
<p>（1）没有TextureCache我们是怎样处理Texture2D对象的？</p>
<p>在没有TextureCache情况下，直接通过string、image、data创建一个Texture2D对象，这时该Texture2D对象的引用计数为1.用该对象构建一个Sprite元素，Sprite首先对其进行retain以确保纹理对象不被删除，并在被移出场景时release该Texture2D对象。这时，Texture2D的生命周期取决于我们是否不要继续使用它。但是，无论如何，我们都需要记住每个Texture2D对象对应于哪一张图片，而且还要让这些独立的Texture2D对象在其他类中被使用要费一番周折。</p>
<p>（2）使用TextureChace怎样对TextureCache进行管理？</p>
<p>TextureCache中每个Texture2D对象的引用计数是1，如果有元素正在使用该纹理，则引用计数为正在使用的元素个数加1。1表示该纹理处于空闲状态，我们可以通过使用removeUnusedTexture()方法来移除空闲的纹理释放资源。</p>
<p>如果确定某个纹理不再使用，则可以使用removeTexture()方法从TextureCache中移除该纹理，这时Texture2D对象将执行一次release，其引用计数将等于正在被使用的元素的个数。一旦最后一个正在使用的元素的个数。一旦最后一个正在使用的元素释放该纹理，该纹理将删除。如果确定某个时刻之后，所有纹理都不再被使用，则可以使用removeAllTextures()方法从TextureCache中移除所有纹理，示例如下：</p>
<pre><code>void TextureCache::removeTexture(Texture2D* texture)
{
    if(!texture)
    {
        return;
    }

    for(auto if = _textures.cbegin(); it != _texture.cend();)
    {
        if（it-&gt;second == texture）
        {
            texture-&gt;release();
            _textures.erase(i++);
            break;
        } else
            ++it;
    }
}
</code></pre><h5 id="9-3-场景过度中的资源管理"><a href="#9-3-场景过度中的资源管理" class="headerlink" title="9.3 场景过度中的资源管理"></a>9.3 场景过度中的资源管理</h5><p>在游戏中每个每个资源对生命周期有不同的周期，如下：</p>
<ul>
<li>有些资源在游戏开始时就需要载入，并且驻留在内存中，直至整个游戏结束，如每个场景通用的一些按钮等元素；</li>
<li>有些资源的生命周期对应于特定的场景，如关卡资源；</li>
<li>一些剧情或者过场动画类资源的生命周期则比较短暂，它们在使用之后会立即被销毁；</li>
<li>还有一些资源很难定义其生命周期，如跑酷游戏中的资源怀玩家跑动的距离有关，这里需要小心的进行动态预加载。</li>
</ul>
<p>我们并不能简单的通过TextureCache来解决这个问题，我们需要一种新的机制来管理我们预期要使用的资源，它不能依赖运行时引用机制，其中一条比较简单的机制就是对资源使用引用计数。</p>
<p>（1）基于引用计数的资源管理</p>
<p>此处的引用计数不是指当前该资源在内存中被引用的次数，而是应用程序在逻辑上使用哪些资源。其工作流程如下：</p>
<ol>
<li>在进入新场景（或者关卡）时，对该场景需要使用的所有资源的引用计数+1.这里这些资源还可以未被载入内存；</li>
<li>对上一个场景（或者关卡）使用的所有资源的引用计数-1；</li>
<li>删除引用计数为0的资源（表示下一个场景不需要使用这些资源）；</li>
<li>载入引用计数为1的资源，这些资源可能是新场景中增加的资源，也可能是场景之前一直存在的资源。</li>
</ol>
<p>（2）更好的场景过渡资源管理</p>
<p>Cocos2d-x中没有提供场景或者关卡层面上的资源管理解决方案，只提供了文件加载、纹理创建、缓存、删除及共享，要想实现高效的资源管理，需要我们进行一定的封装。</p>
<p>结合Cocos2d-x对纹理缓存管理的机制，我们可以容易地构建一个简单的资源管理方案，其中缓存机制用来处理资源运行时的创建、缓存、删除及共享，而上层的引用计数用来管理多个场景之间资源的过渡各共享，如图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0917%E5%9C%BA%E6%99%AF%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86.JPG" alt=""></p>
<ul>
<li>XXXCache对方于一种资源的解析和缓存，安应该和TextureCache一样，对每个路径进行缓存以共享内容，并将它们解析成特定的数据缓存起来，它们负责的是资源内存引用的管理；</li>
<li>ResourseManager则负责逻辑上的资源引用计数管理。其主要作用是解决场景之间的资源共享，它可以管理任何类型的资源，为了方便，我们也会将资源的加载等操作封装到ResourceManager中，应用程序只需要和ResourceManager交互。</li>
</ul>
<p>需要注意的是，Cocos2d-x对纹理的创建和管理是不会经过ResourceManager的，所以，应该尽量让场景和关卡需要使用的资源列表中包含所有该场景需要使用的纹理，否则ResourceManager将无法管理这部分资源。</p>
<h5 id="9-4-Android下的纹理恢复-处理"><a href="#9-4-Android下的纹理恢复-处理" class="headerlink" title="9.4 Android下的纹理恢复 处理"></a>9.4 Android下的纹理恢复 处理</h5><p>在Android系统中，当应用程序由前台切换到后台时，OpenGL ES的上下文有可能被重新创建，这时应用程序会丢失所有纹理。Cocos2d-x中通过VolatileTextureMgr来处理这个问题。</p>
<p>VolatileTextureMgr记录了应用程序中当前正在使用的所有纹理一切相关信息，这些信息用来重新构建该纹理，每个纹理的信息用一个VolatileTexture对象来记录。根据纹理不同的创建方式，VolatileTexture对象拥有不同的属性值，示例如下：</p>
<pre><code>class VolatileTexture
{
    typedef enum{
        kInvalid = 0,
        kImageFile,
        kImageData,
        kString,
        kImage,
    }ccCachedImageType;
private:
    VolatileTexture(Texture2D *t);
    ~VolatileTexture();

protected:
    friend class VolatileTextureMgr;
    Texture2D *_texture;

    Image *_uiImage;

    ccCashedImageType _cashedImageType;

    void *_textureData;
    int _dataLen;
    Size _textureSize;
    Texture2D::PixelFormat _pixelFormat;

    std::string _fileName;

    Texture2D::TexParams _texParams;
    std::string _text;
    FontDefinition _fontDefinition;
}
</code></pre><p>VolatileTexture对象包含纹理的路径。如果通过data和Image创建，则包含_textureData和_uiImage属性值。此外，它还包含纹理的过滤模式、字体定义（用于描述字体创建的纹理）等信息。</p>
<p>当然，VolatileTextureMgr对纹理的缓存会额外占据一些内存，尤其是通过data和Image创建的纹理，这些数据在内存中才能用来恢复纹理。</p>
<h3 id="10-纹理所占内存的计算"><a href="#10-纹理所占内存的计算" class="headerlink" title="10 纹理所占内存的计算"></a>10 纹理所占内存的计算</h3><p>纹理所占内存的大小 result = size.width <em> size.height </em> bpp / 8</p>
<ul>
<li>result单位为byte；</li>
<li>bpp的全称是Bits per Pixel，表示每个像素占多少位，通过bpp我们就可以知道每个纹理所占的GL内存了；</li>
</ul>
<p>例如分辨率为1024 × 1024 × 32 /8 = 19304 byte即4MB； </p>
<table>
<thead>
<tr>
<th>纹理格式</th>
<th>bpp</th>
<th>是否包含Alpha通道 </th>
</tr>
</thead>
<tbody>
<tr>
<td>BGRA8888</td>
<td>32</td>
<td>是</td>
</tr>
<tr>
<td>RGBA8888</td>
<td>32</td>
<td>是</td>
</tr>
<tr>
<td>RGB888</td>
<td>24</td>
<td>否</td>
</tr>
<tr>
<td>RGB565</td>
<td>16</td>
<td>否</td>
</tr>
<tr>
<td>A8</td>
<td>8</td>
<td>否</td>
</tr>
<tr>
<td>I8</td>
<td>8</td>
<td>否</td>
</tr>
<tr>
<td>AI88</td>
<td>16</td>
<td>否</td>
</tr>
<tr>
<td>RGBA4444</td>
<td>16</td>
<td>是</td>
</tr>
<tr>
<td>RGB5A1</td>
<td>16</td>
<td>1位alpha</td>
</tr>
<tr>
<td>PVRTC4</td>
<td>4</td>
<td>是</td>
</tr>
<tr>
<td>PVRTC4A</td>
<td>4</td>
<td>是</td>
</tr>
<tr>
<td>PVRTC2</td>
<td>2</td>
<td>是</td>
</tr>
<tr>
<td>PVRTC2A</td>
<td>2</td>
<td>是</td>
</tr>
<tr>
<td>ETC</td>
<td>4</td>
<td>否</td>
</tr>
<tr>
<td>S3TC_DXT1</td>
<td>4</td>
<td>1位alpha</td>
</tr>
<tr>
<td>S3TC_DXT3</td>
<td>8</td>
<td>是</td>
</tr>
<tr>
<td>S3TC_DXT5</td>
<td>8</td>
<td>是</td>
</tr>
<tr>
<td>ACT_RGB</td>
<td>4</td>
<td>否</td>
</tr>
<tr>
<td>ATC_EXPLICIT_APPHA</td>
<td>8</td>
<td>是</td>
</tr>
<tr>
<td>ATC_INTERPOLATED_APPHA</td>
<td>8</td>
<td>是</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/3.1（2） 纹理压缩及应用/" data-id="cjov31rhy000p88rif2ppwdoi" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/3.1（1） 纹理" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/3.1（1） 纹理/" class="article-date">
  <time datetime="2018-11-24T03:55:32.964Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/3.1（1） 纹理/">3.1 纹理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>纹理的重要性体现在下面两个方面：</p>
<p>（1）3D图形渲染最重要的工作之一是将纹理应用到物体表面，这片过程主要发生在片段着色器工作阶段，使用光栅化阶段插值计算得出的纹理坐标从纹理中采样，然后对片段进行着色，可以处理丰富的物资，如光照、阴影等。纹理是其实现的重要基础。</p>
<p>（2）纹理的存储格式影响着应用程序包的大小，也占据的应用程序的大部分内存。游戏开发中对纹理进行各个层面的优化是一项重要的工作，只有了解纹理的一切内容，才能知道怎样对其进行优化。</p>
<p>在Cocos2d-x中主要通过Texture2D类来创建各管理OpenGL ES纹理，下面将对纹理的格式、多级纹理、纹理的绑定、以及怎样在内存中管理纹理，以及各种压缩纹理的处理方法。</p>
<h3 id="1-光栅化"><a href="#1-光栅化" class="headerlink" title="1 光栅化"></a>1 光栅化</h3><p>在OpenGL ES渲染管线中，光栅化阶段用于将投影到2D屏幕上的图元转换为帧缓冲中整数坐标位置上的片段，每个片段都会包含颜色、深度和模板值。因此光栅化分为两个步骤：</p>
<ul>
<li>确定视窗上哪些整数位置的片段需要被图元覆盖。</li>
<li>对图元进行插值计算，得出每个片段的颜色和深度。</li>
</ul>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0831%E7%BA%BF%E6%AE%B5%E7%9A%84%E5%85%89%E6%A0%85%E5%8C%96.JPG" alt=""></p>
<p>插值计算后得出的这些颜色各深度值将进行后续阶段（片段操作）进行处理，最后的结果将用于更新帧缓冲上该位置信息。</p>
<p>每个片段的颜色值由片段着色器决定，片段着色器会使用光栅化生成一些易变量（Varying）变量。例如，纹理坐标用于计算颜色值，片段的深度值由光栅化决定。</p>
<h6 id="1-1-多重采样"><a href="#1-1-多重采样" class="headerlink" title="1.1 多重采样"></a>1.1 多重采样</h6><p>（1）概念</p>
<p>在光栅化过程中，由于屏幕量由离散的像素点组成的，所以在对图元采样时可能会丢失一部分信息，导致边缘出现锯齿，如图所示，左图为默认情况下在Cocos2d中使用DrawNode绘制的倾斜线段，出现了明显的锯齿。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0831%E5%85%89%E6%A0%85%E5%8C%96%E4%BA%A7%E7%94%9F%E7%9A%84%E9%94%AF%E9%BD%BF.JPG" alt=""></p>
<p>在OpenGL ES中使用多重采样（MultiSampling）解决这个问题。与单重采样不同的是，帧缓冲上的每个像素不是来自片段中心位置的采样，而是基于附近多个位置的采样共同决定的一个颜色值。</p>
<p>相对于单重采样，帧缓冲额外的多重采样缓冲区来存储这些额外采样点的颜色、深度各模板值，这使得图元的边缘能够比较平滑的过渡。图右为开启多重采样的情况下使用Cocos2d-x中DrawNode绘制的线段。</p>
<p>（2）使用</p>
<p>Cocos2d中默认的情况下是不开启多重采样，需要手动修改CCEAGLView的初始化方法的multiSampling参数来开启。方法如下：</p>
<pre><code>- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions
{
    CCEAGLView *eaglView = [CCEAGLView viewWithFrame:[window bounds]
        pixelFormat: kEAGLColorFormateRGBA8
        depthFormat:GL_DEPTH24_STENCIL8_OES
        perserveBackbuffer: NO
        sharegroup: nil
        multiSampling: NO
        numberOfSamples:0
    ];
}
</code></pre><ul>
<li>multiSampling:设为YES，则开启多重采样。</li>
<li>muberOfSamples:每个片段包含的邻近采样点的数量，数量越多，抗锯齿效果越明显，但相应的也会影响性能。这个最大数量受硬件支持的限制，我们可以通过getIntegerv(GL_MAX_SAMPLES)来查询当前硬件支持的最大数量。</li>
</ul>
<p>（3）总结</p>
<p>关于多重采样的总结如下：</p>
<ul>
<li>多重采样反锯齿广泛应用于3D游戏开发中，在一般的2D游戏开发中，大部精灵都是规则且垂直于摄像机的矩形区域，所以锯齿现象不是很明显，但是如果游戏中需要绘制一些不规则的线段或者多边形，最好开启多重采样。</li>
<li>开启多重采样之后，缓冲区的像素信息不再被存储到帧缓冲中，而是被存储到一个特殊的多重采样缓冲区中。</li>
<li>多重采样只能在初始化OpenGL ES时设置，之后不能被修改，这是因为多重采样与单个像素点采样在实现机制上有很大区别。</li>
<li>OpenGL ES的多重采样只是针对多边形的边缘进行抗锯齿处理，对应用程序的性能影响较小。</li>
</ul>
<h5 id="1-2-纹理坐标"><a href="#1-2-纹理坐标" class="headerlink" title="1.2 纹理坐标"></a>1.2 纹理坐标</h5><p>OpenGL ES中纹理坐标以左下角为原点。纹理坐标有两种度量形式：</p>
<ul>
<li>顶点在纹理中的纹理坐标。用（u, v）表示，u和v的最大值分别是纹理的宽度和高度，它的值通常由客户端应用程序提供。</li>
<li>在片段着色器中使用的片段纹理坐标。通常用（s, t）表示，取值范围为（0.0， 0.0）~（1.0， 1.0）。这一规化过程是在光栅化阶段完成的。如下图所示：</li>
</ul>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0831%E7%BA%B9%E7%90%86%E5%9D%90%E6%A0%87.JPG" alt=""></p>
<h3 id="2-像素矩形"><a href="#2-像素矩形" class="headerlink" title="2 像素矩形"></a>2 像素矩形</h3><p>概念：</p>
<p>（1）像素矩形：一个抽象的概念，它表示一个矩形区域的二维像素数组。它可以用来表示一个矩形区域的颜色、深度或者模板值，对应其数组的每个像素值分别表示颜色、深度和模板。</p>
<p>（2）纹理：通过TexImage2D及相关命令定义的像素矩形称为纹理。纹理由纹理像素（Texels）简称纹素组成。2D纹理由二维纹素组成，纹理的宽度表示数组的列数，高度表示数组的行数，数组中的第一个元素表示纹理左下角的像素点。3D纹理则增加了深度，由3维的纹理像素组成。</p>
<p>（3）解包：将客户端的颜色数据传输至GL服务端称为解包。</p>
<p>（4）打包：将服饰端像素矩形的像素数据读取到客户端的过程称之为打包。</p>
<p>存储颜色的像素矩形可以通过TexImage2D及相关命令定义，并将数据由客户端内存中传输至GL服务端内存中，或者通过ReadPixels及相关命令将数据从帧缓冲区中读取到客户端内存中。</p>
<h5 id="2-1-像素存储模式"><a href="#2-1-像素存储模式" class="headerlink" title="2.1 像素存储模式"></a>2.1 像素存储模式</h5><p>在纹理传输过程中，所有用于控制客户端中的纹素编码的参数都使用PixeStorei命令 void PixelStorei(enum pname, T param) 来设置。PixelStorei命令会影响TexImage2D、ReadPixels及其他像素矩形数据传输相关命令。对于表示颜色值的纹理数据，基参数值如下表：</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>类型</th>
<th>初始值</th>
<th>合法值</th>
</tr>
</thead>
<tbody>
<tr>
<td>UNPACK_ALIGNAMENT</td>
<td>integer</td>
<td>4</td>
<td>1, 2, 4, 8</td>
<td></td>
</tr>
</tbody>
</table>
<h5 id="2-2-纹理数据的传输"><a href="#2-2-纹理数据的传输" class="headerlink" title="2.2 纹理数据的传输"></a>2.2 纹理数据的传输</h5><p>解包中，输入的是客户端内存中以某种方式编码的像素数据，输出的是值[0, 1]的浮点型RGBA像素值，接下来将按照这个传输过程的顺序解释纹理数据的传输。</p>
<p>（1）命令参数：</p>
<p>任何传输或者返回像素矩形的命令都需要包含一些基本参数（当然，特定的传输过程还需要额外的参数，如glTexImage2D），如format、width、height、data、type。</p>
<ul>
<li>data：表示客户端内存中像素矩形数组的指针，也可能指向一个缓冲对象的偏移值。该数组是一个ubyte或者ushort数组，数组中的元素被按1、2、3或4分量形成一个组的集合。</li>
<li>format：表示一个像素矩形中数据的构成，及描述data中每个组的构成，包括每个分量的构成及数据。</li>
<li>type：每个像素矩形分量构成（表第一列）及Data数组中每个元素的数据类型（表第二列）。</li>
</ul>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>GL数据类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>UNSIGNED_BYTE</td>
<td>ubyte</td>
</tr>
<tr>
<td>UNSIGNED_SHORT_5_6_5</td>
<td>ushort</td>
</tr>
<tr>
<td>UNSIGNED_SHORT_4_4_4_4</td>
<td>ushort</td>
</tr>
<tr>
<td>UNSIGNED_SHORT_5_5_5_1</td>
<td>ushort</td>
</tr>
</tbody>
</table>
<p>按照类型，一个像素矩形可能表示的是颜色值、深度值、模板值，以及深度与模板共同构成的数据值。一个颜色值最多由4个分量构成；深度值和模板值分别由一个分量构成；深度与模板共同构成的数据值则由2个分量构成。所有这些可能的纹理格式如下表。ReadPiexels可以接受这个格式的一个子集。</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>分量意义及顺序</th>
<th>初始值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>ALPHA</td>
<td>A</td>
<td>Color       </td>
</tr>
<tr>
<td>RGB</td>
<td>R, G, B</td>
<td>Color       </td>
</tr>
<tr>
<td>RGBA</td>
<td>R, G, B, A</td>
<td>Color       </td>
</tr>
<tr>
<td>LUMINANCE</td>
<td>Luminance</td>
<td>Color       </td>
</tr>
<tr>
<td>LUMINANCE_ALPHA</td>
<td>Luminance, A</td>
<td>Color       </td>
</tr>
</tbody>
</table>
<p>对于表示颜色的像素矩形，每个分量（R、G、B、A）在数组中所占的位数可能并不相同。例如，一个16位的颜色缓冲区可能由5位红色、5位蓝色、6位绿色组成。</p>
<h5 id="2-3-解包"><a href="#2-3-解包" class="headerlink" title="2.3 解包"></a>2.3 解包</h5><p>（1）格式和类型</p>
<p>format描述了像素矩形的数据类型（颜色深度或者模板）；type定义了像素数据分量的构成，因此所有编格式的像素矩形的数量由format和type共同决定。实际上并不是所有的组合都是合法的。OpenGL ES支持的所有像素格式和类型的组合如下表所示：</p>
<table>
<thead>
<tr>
<th>格式名称（format）</th>
<th>类型（type）枚举</th>
<th>bytes/pixel </th>
</tr>
</thead>
<tbody>
<tr>
<td>RGBA</td>
<td>UNSIGNED_BYTE</td>
<td>4       </td>
</tr>
<tr>
<td>RGB</td>
<td>UNSIGNED_BYTE</td>
<td>3       </td>
</tr>
<tr>
<td>RGBA</td>
<td>UNSIGNED_SHORT_4_4_4_4</td>
<td>2       </td>
</tr>
<tr>
<td>RGBA</td>
<td>UNSIGNED_SHORT_5_5_5_1</td>
<td>2       </td>
</tr>
<tr>
<td>RGB</td>
<td>UNSIGNED_SHORT_5_5_6</td>
<td>2       </td>
</tr>
<tr>
<td>LUMINANCE_ALPHA</td>
<td>UNSIGNED_BYTE</td>
<td>2       </td>
</tr>
<tr>
<td>LUMINANCE</td>
<td>UNSIGNED_BYTE</td>
<td>1       </td>
</tr>
<tr>
<td>ALPHA</td>
<td>UNSIGNED_BYTE</td>
<td>1       </td>
</tr>
</tbody>
</table>
<p>如果type类型是UNSIGNED_BYTE，则表示每个分量分别占据1个byte；而如果就其他类型，则表示所有分量共享一个ushort。由此可以看出，OpenGL ES最多支持32位颜色值。</p>
<p>（2）对齐方式</p>
<p>对于像素矩形数据的传输，适当的选择内存中数据的对齐方式，能提升数据的传输的性能。UNPACK_ALIGNMENT用于指明内存中数据是按多少位对齐的，即每行中所有分量的数据（按位算）是UNPACK_ALIGNMENT的整数倍。例如，对于分量数据类型UNSIGNED_BYTE的RGB(A)，可以按照8位对齐。Cocos2d-x中按照纹理像素宽度的位数设置对齐方式，示例如下：</p>
<pre><code>bool Texture2D::initWithMipmaps(MipmapInfo* mipmaps, int mipmapsNum, PixelFormat pixelFormat, int pixelsWide, int pixelsHigh)
{
    // set the row align only when mipmapsNum == 1 and the data is uncompressed
    if (mipmapsNum == 1 &amp;&amp; !info.compressed)
    {
        unsigned int bytesPerRow = pixelsWide * info.bpp / 8;
        if (bytesPerRow % 8 == 0) {
            glPixelStorei(GL_UNPACK_ALIGNMENT, 8);
        } else if (bytesPreRow % 4 == 0){
            glPixelStorei(GL_UNPACK_ALIGNMENT, 4);
        } else if (bytesPreRow % 2 == 0){
            glPixelStorei(GL_UNPACK_ALIGNMENT, 2);
        } else{
            glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
        }
    } else {
        glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
    }
}
</code></pre><p>对于type为UNSIGNED_SHORT_5_6_5、UNSIGNED_SHORT_4_4_4_4或者UNSIGNED_SHORT_5_5_5_1的类型，它们所有的分量构成的组被包装为一个短整形（ushort）,它们的分量的组成及每个分量占据的位数是根据type计算出来的，type必须与format保持一致。如下表：</p>
<table>
<thead>
<tr>
<th>类型（type）枚举</th>
<th>GL数据类型</th>
<th>分量数量</th>
<th>格式名称（format）    </th>
</tr>
</thead>
<tbody>
<tr>
<td>UNSIGNED_SHORT_5_5_6</td>
<td>ushort</td>
<td>3</td>
<td>RGB                   </td>
</tr>
<tr>
<td>UNSIGNED_SHORT_4_4_4_4</td>
<td>ushort</td>
<td>4</td>
<td>RGBA                  </td>
</tr>
<tr>
<td>UNSIGNED_SHORT_5_5_5_1</td>
<td>ushort</td>
<td>4</td>
<td>RGBA                  </td>
</tr>
</tbody>
</table>
<p>对于短整形的像素格式，每一个像素占据16位内存；</p>
<ul>
<li>UNSIGNED_SHORT_5_6_5，用于存储一个16位不包含透明通道的纹理；</li>
<li>UNSIGNED_SHORT_4_4_4_4，用于存储一个16位包含透明通道的纹理；</li>
<li>UNSIGNED_SHORT_5_5_5_1，只用1位来保存透明通道，其每个像素要么透明，要么不透明；使颜色有道有更高的精度，适合表示字体或蒙板；</li>
</ul>
<p>每个分量占据的位数如下图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0901%E7%9F%AD%E6%95%B4%E5%9E%8B%E5%83%8F%E7%B4%A0%E5%88%86%E9%87%8F%E7%9A%84%E6%9E%84%E6%88%90.JPG" alt=""></p>
<p>（3）解包流程图：</p>
<p>输出RGBA像素值，将像素矩形传输至GL的流程图如下：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0901%E5%B0%86%E5%83%8F%E7%B4%A0%E7%9F%A9%E5%BD%A2%E4%BC%A0%E8%BE%93%E8%87%B3GL%EF%BC%8C%E8%BE%93%E5%87%BARGBA%E5%83%8F%E7%B4%A0%E5%80%BC.JPG" alt=""></p>
<p>在所有类型、格式的数据被解包之后，它们的byte或者short类型的值被转换为浮点型，实际上是执行归一化计算，将无符号的整形转换为[0, 1]浮点型，将有符号的整型转换为[-1, 1]的浮点型。</p>
<p>在转换为浮点型之后，还需要反所有类型转换为RGB格式，这主要是针对LUMINANCE和LUMINANCE_ALPHA两种类型，对于LUMINANCE其一个分量会被转换为R、G、B这三个分量的值；LUMINANCE_ALPHA类型，其两个分量会被转化为R、G、B、A这4个分量，R、G、B这三个分量的值被复制为LUMINANCE分量的值，而A的值被复制为ALPHA分量的值。</p>
<p>最后，每个组均被转换为4个分量，如果组中不包含A分量，则A分量的值为1.0，如果缺少R、G、B分量，则其值为0。</p>
<p>这样，一个像素矩形就被解包为一个颜色值上传到GL缓冲区。</p>
<h3 id="3-客户端图像格式"><a href="#3-客户端图像格式" class="headerlink" title="3 客户端图像格式"></a>3 客户端图像格式</h3><p>上面小节中的纹理格式及数据类型，都是指纹理在GL服务端中的存储模式。在将纹理传输到<br>GL服务端以供片段着色器使用时，我们必须指明纹理在GL服务端以怎样的方式存储，这需要通过TexImage2D来设置。</p>
<p>客户端和服务端的图像：</p>
<p>客户端的图像资源通常压缩为PNG或者JPG格式，以占用更少的磁盘空间；但在服务端，为了保证实时的渲染性能，服务端的纹理数据通常是未压缩的（压缩纹理除外），因为这样能够保证最快的读取速度。</p>
<p>因此，客户端在传输纹理时首先需要解压图像资源，将其转换为GL服务端支持的纹理格式，才能保证纹理的正确使用。这涉及两方面内容：</p>
<ul>
<li>客户端图像格式与服务端一一对应；</li>
<li>客户端图像数据在各种格式之间的转换；</li>
</ul>
<h5 id="3-1-纹理格式的对应关系"><a href="#3-1-纹理格式的对应关系" class="headerlink" title="3.1 纹理格式的对应关系"></a>3.1 纹理格式的对应关系</h5><p>PixelFormat枚举定义了Cocos2d-x支持的图像格式，程序中添加的所有图像资源，最后都要转换为这些格式才能被使用。以下是PixelFomat枚举的定义，这里省去了压缩纹理格式：</p>
<pre><code>class CC_DLL Texture2D : public Ref
{
public:
    enum class PixelFormat
    {
        BRGA8888,
        RGBA8888,
        RGB888,
        RGB565,
        A8,
        I8,
        AI88,
        RBGA4444,
        RGB5A1,
    }
}
</code></pre><p>每个客户端的格式都对应于服务端格式的一种，在Cocos2d中，自定义类型PixelFormatInfoMap定义了它们与OpenGL ES纹理格式的转换关系，如下表（依然省去了压缩格式）。</p>
<table>
<thead>
<tr>
<th>客户端名称</th>
<th>GL格式(format)</th>
<th>客户端格式(format)</th>
<th>GL数据类型(type) </th>
</tr>
</thead>
<tbody>
<tr>
<td>BGRA8888</td>
<td>GL_RGBA</td>
<td>GL_BGRA</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
<tr>
<td>RGBA8888</td>
<td>GL_RGBA</td>
<td>GL_RGBA</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
<tr>
<td>RGBA4444</td>
<td>GL_RGBA</td>
<td>GL_RGBA</td>
<td>GL_UNSIGNED_SHORT_4_4_4_4</td>
</tr>
<tr>
<td>RGB5A1</td>
<td>GL_RGBA</td>
<td>GL_RGBA</td>
<td>GL_UNSIGNED_SHORT_5_5_5_1</td>
</tr>
<tr>
<td>RGB565</td>
<td>GL_RGB</td>
<td>GL_RGB</td>
<td>GL_UNSIGNED_SHORT_5_6_5</td>
</tr>
<tr>
<td>RGB888</td>
<td>GL_RGB</td>
<td>GL_RGB</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
<tr>
<td>A8</td>
<td>GL_ALPHA</td>
<td>GL_ALPHA</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
<tr>
<td>I8</td>
<td>GL_LUMINANCE</td>
<td>GL_LUMINANCE</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
<tr>
<td>AI888</td>
<td>GL_LUMINANCE_ALPHA</td>
<td>GL_LUMINANCE_ALPHA</td>
<td>GL_UNSIGNED_BYTE</td>
</tr>
</tbody>
</table>
<h5 id="3-2-图像数据格式转换"><a href="#3-2-图像数据格式转换" class="headerlink" title="3.2 图像数据格式转换"></a>3.2 图像数据格式转换</h5><p>应用程序中的图像资源通常用使用PNG、JPG之类的压缩格式，所以客户端需要在不同格式之间对图像数据进行转换。例如使用JPG的时候，Texture2D需要将JPG格式的图像数据转换为RGBA8888格式的数据。再如，出于对游戏性能的考虑，应用程序也可以将高分辨率的RGBA8888转换为低分辨率的RGBA4444。</p>
<p>Texture2D提供了一个convertDataToFormat()方法来实现不同数据之间的转换，Texture2d在通过Image实例进行初始化的时候完成这个数据转换过程。如下：</p>
<pre><code>class CC_DLL Texture2D : public Ref
{
public:
    static PixelFormat convertDataToFormat(const unsigned char* data, ssize_t dataLen, PixelForamt originFormat, PixelFormat format, unsigned char** outData, ssize_t* outDataLen);
}

bool Texture2D::initWithImage(Image* image)
{
    return initWithImage(image, PixelFormat::NONE);
}

bool Texture2D::initWithImage(Image *image, PixelForamt format)
{
    unsigned char* tempData = image-&gt;getData();

    if (image-&gt;getNumberOfMipmaps() &gt; 1){
    } else if (image-&gt;isCompressed()) {
    } else {
        if (format != PixelForamt::NONE){
            pixelFormat = g_defaultAlphaPixelFormat;
        } else {
            pixelFormat = format
        }

        unsigned char* outTempData = nullptr;
        ssize_t outTempDataLen = 0;

        pixelFormat = convertDataToFormat(tempData, tempDataLen, renderFormat, pixelFormat, &amp;outTempData, &amp;outTempDataLen);

        initWithData(outTempData, outTempDataLen, pixelFormat, imageWidth, imageHeight, imageSize);

        if (outTempData != nullptr &amp;&amp; outTempData != tempData)
        {
            delete [] outTempData;
        }
        return true;
    }
}
</code></pre><p>如果目标格式为AUTO类型，则该方法会尝试将其转换为一种最接近的格式。在这里，format被设置为PixelFormat::NONE。这样，initWithImage就会使用g_defaultAlphaPixelFormat的值，g_defaultAlphaPixelFormat的默认值为“AUTO”，示例如下：</p>
<pre><code>static Texture2D::PixelFormat g_defaultAlphaPixelFormat = Texture2D::PixelFormat::DEFAULT
// DEFAULT = AUTO
</code></pre><p>实际上，在应用程序初始化的时候，其值默认为“RGBA8888”，即所有的资源将被转换为RGBA8888格式，在GL中，每个像素占据32位的内存，如下：</p>
<pre><code>void Director::setDefaultValues(void)
{
    Configuration *conf = Configuration::getInstance();

    std::string pixel_format = conf-&gt;getValue(&quot;cocos2d.x.texture.pixel_format_for_png&quot;, Value(&quot;rgba8888&quot;)).asString();

    if (pixel_format == &quot;rgba8888&quot;)
        Texture2D::setDefaultAlphaPixelForamt(Texture2D::PixelFormat::RGBA8888);
    else if (pixel_format == &quot;rgba44444&quot;)
        Texture2D::setDefaultAlphaPixelForamt(Texture2D::PixelFormat::RGBA4444);
    if (pixel_format == &quot;rgba5551&quot;)
        Texture2D::setDefaultAlphaPixelForamt(Texture2D::PixelFormat::RGBA5551);
}
</code></pre><p>在实际开发中，我们可以将其指定为AUTO，这样，JPG就会被转换为RGB888而不是RGBA8888，减少了1/4内存的浪费。当然，如果图像资源中同时包含多种格式，则需要小心设置。</p>
<h3 id="4-纹理对象和加载纹理"><a href="#4-纹理对象和加载纹理" class="headerlink" title="4 纹理对象和加载纹理"></a>4 纹理对象和加载纹理</h3><p>在绘图管线中，纹理主要在片段着色器中被使用。每一次绘制命令（glDrawArray或者glDrawElements）执行时，需要告诉OpenGL ES当前管线中使用的一个或者多个纹理（Multitexturing）, 这需要涉及创建纹理对象、绑定纹理对象、将纹理数据加载到OpenGL ES内存中等命令操作。</p>
<p>（1）创建和销毁</p>
<p>一个纹理对象是一个数据集，它持有该纹理被使用时需要用到的所有数据，这些数据包括图像像素数据、过滤（Filtering Mode）模式、扩展模式（Wrap Mode）等。在OpenGL ES中，用一个无符号的整数表示该纹理对象的名称，纹理对象使用glGenTextures命令创建各销毁，示例如下：</p>
<pre><code>void glGenTextures(GLsizei n, GLuint *textures);
void glDeleteTextures(GLsizei n, GLuint *textures);
</code></pre><ul>
<li>n，表示需要创建纹理对象的数量；</li>
<li>textures，用于保存分配的纹理名称；</li>
</ul>
<p>（2）绑定</p>
<p>创建一个纹理对象后，为了操作该纹理对象，我们必需绑定纹理对象。由于应用程序中并不直接持有纹理对象指针，所以，OpenGL ES通过设定当前纹理对象对其进行操作。</p>
<pre><code>void glBindTexture(GLenum target, GLuint texture);
</code></pre><p>设定当前纹理对象之后，后续（直到纹理对象被删除或者下一个纹理绑定命令被执行之前）的操作（如glTexImage2D和glTexParameter）将作用在该纹理对象上。</p>
<p>（3）加载到OpenGL ES内存</p>
<p>绑定当前纹理对象之后，就可以将纹理对象加载到内存中了。在OpenGL ES中，主要使用glTexImage2D命令加载纹理。一旦该命令被执行，就会立即将图像像素数据从客户端传输至服务端内存中，后续对客户端数据的修改不会影响到OpenGL ES中绑定的纹理数据。因此，客户端在将数据加载至OpenGL ES内存中之后，应该立即删除客户端图像数据缓存对象。</p>
<pre><code>void glTexImage2D(GLenum target, GLint level, GLenum internalFormat, GLsize width, GLsizei height, GLint border, GLenum format, GLenum type, const void* pixels);
</code></pre><ul>
<li>target，表示GL_TEXTURE_2D或者立方体纹理的一个面；</li>
<li>level，表示多极纹理的级别；</li>
<li>internalFormat，表示纹理在GL中的存储格式；</li>
<li>width、height，表示纹理尺寸；</li>
<li>fromat，表示客户端图像数据的构成及顺序；</li>
<li>type，表示GL中纹理的格式及数据类型；</li>
<li>pixel，表示客户端的图像数据缓冲对象；</li>
</ul>
<p>通过以上步骤，就可以创建、加载纹理，或者修改纹理的绘制模式了，Cocos2d-x在创建一个Texture2D对象时会执行以上命令，每个Textue2D对象对应一个纹理对象，Texture2D类向应用程序提供了一个简单的创建和管理纹理对象的方式。</p>
<pre><code>bool Texture2D::initWithMipmaps(MipmapInfo* mipmaps, int mipmapsNum, PixelFormat pixelFormat, int pixelsWide, int pixelsHigh)
{
    glGenTextures(1, &amp;_name);
    GL::bindTexture2D(_name);

    if (mipmapNum == 1)
    {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    } else {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_NEAREST);
    }

    glTexParameteri(GL_TEXTURE_2D, GL_TEXUTRE_MAG_FILTER, GL_LINEAR
    glTexParameteri(GL_TEXTURE_2D, GL_TEXUTRE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXUTRE_WRAP_T, GL_CLAMP_TO_EDGE);

    CHECK_GL_ERROR_DEBUG();

    // specify OpenGL texture image
    int width = pixelsWide;
    int height = mipmaps[i].len;

    for (int i = 0, i &lt; mipmapsNum; i++)
    {
        unsigned char *data = mipmaps[i].address;
        GLsizei datalen = mipmaps[i].len;

        if (info.compressed)
        {
            glCompressedTexImage2D(GL_TEXTURE_2D, i, info.internalFormat, (GLsizei)width, (GLsize)height, 0, detalen, data);
        } else {
            glTexImage2D(GL_TEXTURE_2D, i, info.internalFormat, (GLsizei)width, (GLsize)height, 0, info.format, info.type, data);
        }
        width = MAX(width &gt;&gt; 1, 1);
        height = MAX(height &gt;&gt; 1, 1);
    }
return ture;
</code></pre><p>}</p>
<p>纹理一旦被传输至GL服务器，就会一直驻留在GPU内存中，因此，我们应该留意那些不再被使用的纹理，及时地从GL内存中删除它们。</p>
<h3 id="5-纹理单元与多重纹理"><a href="#5-纹理单元与多重纹理" class="headerlink" title="5 纹理单元与多重纹理"></a>5 纹理单元与多重纹理</h3><p>OpenGL ES支持在一个绘图管线中使用多个纹理，这通常被用在3D法线贴图等场景中，用来增强画面表现力。我们也可以在片段着色器中使用特定的算法。</p>
<p>OpenGL ES使用纹理单元来管理多个纹理的使用，每个纹理对象都被放到一个纹理单元中去，使用glActiveTexture命令来激活纹理单元：</p>
<pre><code>void glActiveTexture(GLenmu texture)
</code></pre><p>参数texture是一个索引，默认第一个纹理使用GL_TEXTURE0枚举值，基值为0，该纹理对象将作为片段着色器中第一个采样纹理，后续的纹理单元依次使用GL_TEXTURE1、GL_TEXTURE2,硬件支持的最大纹理单元数量可以使用glGetIntegeriv命令查询，参数为GL_MAT_TEXTURE_IMAGE_UNITS。</p>
<p>glActireTexture实际上设置了当前的纹理单元，这样通过bindTexture2D全局方法封装将纹理绑定到该纹理单元。在Cocos2d-x中，通过bindTexture2DN()全局方法封装将纹理绑定到纹理单元，示例如下：</p>
<pre><code>void bindTexture2DN(GLunit textureUnit, GLunit textureId)
{
    glActiveTexture(GL_TEXTURE0 + TEXTUREUnit);
    glBindTexture(GL_TEXTURE2D, textureId);
}
</code></pre><h3 id="6-纹理缩放"><a href="#6-纹理缩放" class="headerlink" title="6 纹理缩放"></a>6 纹理缩放</h3><p>纹理贴图将纹理的一部分区域映射到图元定义的缓冲区域，通常会导致重新构建一幅图像。因为图元会被执行放大。缩小等操作，所以通常纹理中的每个纹素到缓冲区不一定是一一映射的。这个时候如果纹理被放大，一个纹素可能被映射到多个像素点，如果被缩小，多个纹素将被映射到同一个像素点。这两种情况都会导致图像失真。</p>
<p>当检测到图像发生缩放时，OpenGL ES会使用TEXTURE_MIN_FILTER或者TEXTURE_MAG_TILTER来进行纹素过虑，以决定怎样对片段采样。这些过虑模式可以通过前面讲到的glTexParamter来设置。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911%E7%BA%B9%E7%90%86%E7%BC%A9%E6%94%BE.JPG" alt=""></p>
<h5 id="6-1-纹理缩小"><a href="#6-1-纹理缩小" class="headerlink" title="6.1 纹理缩小"></a>6.1 纹理缩小</h5><p>如图所示，多个纹素被映射到一个像素点，导致一部分纹素的物的丢失，丢失纹素可能包含重要的颜色过渡信息，导致贴图失真，在游戏中表现为远景部分失真。</p>
<p>当纹理被缩小时，TEXTURE_MIN_FILTER将决定像素的选择，TEXTURE_MIN_FILTER有两个基本值，分别是GL_NEAREST和GL_LINEAR。</p>
<p>（1）GL_NEAREST会选择纹理坐标中心位置最近的纹素，这种过虑模式比较简单，执行速度快，但是会导致比较严重的失真。例如，高分辨率的图像在低分辨率的设备上会出现一些像素点跳跃比较大的情况。</p>
<p>（2）GL_LINEAR提供了一种更好的过虑模式，它会从纹理坐标中心点附近选择一个2*2的区域，进行双线性插值计算，得出一个合理的颜色值。这样，在纹理被缩小的时，像素点的过渡比较平滑，但是会损失一部分性能，因为该计算过程在每一帧的每个片段都会被执行。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC.jpg" alt=""></p>
<h5 id="6-2-纹理放大"><a href="#6-2-纹理放大" class="headerlink" title="6.2 纹理放大"></a>6.2 纹理放大</h5><p>如果纹理放大，一个纹素会被应用到多个像素点上去，如下图所示，从而出现大块的纯色区域。</p>
<p>在放大的模式下则比较简单；GL_NEAREST仍然是从距离纹理坐标中心最近的纹素进行采样，而GL_LINEAR会从附近4个纹素进行双线性采样，它们的区别如图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911%E7%BA%B9%E7%90%86%E6%94%BE%E5%A4%A7%E9%87%87%E6%A0%B7%E6%A8%A1%E5%BC%8F.jpg" alt=""></p>
<h5 id="6-3-在Cocos2d-x中设置过滤模式"><a href="#6-3-在Cocos2d-x中设置过滤模式" class="headerlink" title="6.3 在Cocos2d-x中设置过滤模式"></a>6.3 在Cocos2d-x中设置过滤模式</h5><p>通过Cocos2d-x给纹理设置过滤模式的方法比较简单，Texture2D提供了3个方法：</p>
<pre><code>void setTexParameters(const Texparams&amp; texParams);
void setAntiAliasTexParameters();
void setAliasTexParameters();
</code></pre><ul>
<li>在setTextParameters方法中可以分别设置各种缩放纹理的过滤模式。TexParams类还可以设置纹理的重复模式，以决定当纹理坐标超出纹理尺寸时的采样行为。</li>
<li>setAliasTexParameters方法和setAliasTexParameters方法则提供了直接设置反锯齿各带锯齿的纹理过滤模式。</li>
</ul>
<p>initWithMipMaps()方法定义了默认的纹理过滤模式，如下：</p>
<pre><code>bool Texture2D::initWithMipmaps(MipmapInfo* mipmaps, int mipmapsNum, PixelForamt pixelForamt, int pixelsWide, int pixelsHigh)
{
    if (mipmapsNum == 1)
    {
        glTexParameterri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    } else {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_NEAREST);
    }
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
}
</code></pre><h3 id="7-多级纹理"><a href="#7-多级纹理" class="headerlink" title="7 多级纹理"></a>7 多级纹理</h3><p>纹理过滤模式可以用来处理适当的纹理缩放，但这不能满足图形应用程序的需求。有如下两点：</p>
<ul>
<li>其纹理可以经过远大于2倍的缩放，这里仍然会出现失真；</li>
<li>移动设备的分辨率差异很大，在不同设备中使用同一个分辨率的资源也会导致其对纹理的缩放比较严重。</li>
</ul>
<p>（1）多级纹理概念</p>
<p>多级纹理（Mipmapping）是一种高效的采样技术，它使图形应用程序可以不通过增加几何级的复杂度来增加场景的视觉复杂度，并使应用程序不依赖图元操作就可以达到真实的画面。</p>
<p>多级纹理通过产生一个图像金字塔来适配不同分辨率的缩放，由于每一级的的纹理是被预先生成的，它只被执行一次，多级纹理甚至可以在资源中生成，所以不会影响渲染性能。</p>
<p>多级纹理的尺寸由原始纹理的尺寸决定，原始纹理从0级开始，每一级的尺寸是上一级尺寸的1/2，所以理论上每级纹理中的每个纹素是由上级纹理附近的4个纹素决定的，从而实现更平滑的缩放。同时，可以推算得出，多级纹理会比原始纹理多占用大约1/3的内存空间。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0911%E5%A4%9A%E7%BA%A7%E7%BA%B9%E7%90%86.jpg" alt=""></p>
<h5 id="7-1-多级纹理的过滤模式"><a href="#7-1-多级纹理的过滤模式" class="headerlink" title="7.1 多级纹理的过滤模式"></a>7.1 多级纹理的过滤模式</h5><p>多级纹理给TEXTURE_MIN_FILTER模式提供了四种选择：</p>
<ul>
<li>GL_NEAREST_MIPMAP_NEAREST：选择最近级别的纹理进行最近点采样；</li>
<li>GL_NEAREST_MIPMAP_LINEAR：选择最近两个级别的纹理进行最近点采样，然后取线性插值；</li>
<li>GL_LINEAR_MIPMAP_NEAREST：选择最近级别的纹理并进行双线性采样；</li>
<li>GL_LINEAR_MIPMAP_LINEAR：选择最近两个级别的纹理，对每个级别的纹理进行双线性采样，然后取两个采样值的线性插值；</li>
</ul>
<p>GL_LINEAR_MIPMAP_LINEAR的表现最好，但也导致相对更多的计算量。在Cocos2d中，默认对多级纹理使用GL_LINEAR_MIPMAP_LINEAR，如下：</p>
<pre><code>bool Texture2D::initWithMipmaps(MipmapInfo* mipmaps, int mipmapsNum, PixelFormat pixelFormat, int pixelsWide, int pixelsHigh)
{
    glGenTextures(1, &amp;_name);
    GL::bindTexture2D(_name);

    if (mipmapNum == 1) 
    {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    } else {
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_NEAREST);
    }

    return true;
}
</code></pre><h5 id="7-2-多级纹理的上传"><a href="#7-2-多级纹理的上传" class="headerlink" title="7.2 多级纹理的上传"></a>7.2 多级纹理的上传</h5><p>glTexImage2D是用于上传图像数据至GL内存的命令，其参数level用于指定纹理的级别。一般情况下，最大纹理使用级别0，,纹理尺寸越小，级别越高。在Cocos2d-x中，可以使用Texture2D::initWithMipmaps来上传多级纹理。示例如下：</p>
<pre><code>bool Texture2D::initWithMipmaps(MipmapInfo* mipmaps, int mipmapsNum, PixelFormat pixelFormat, int pixelsWide, int pixelsHigh)
{
    for (int i = 0; i &lt; mipmapsNum; i++)
    {
        unsigned char *data = mipmaps[i].address;
        GLsizei datalen = mipmaps[i].len;

        if (info.compressed)
        {
            glCompressedTexImage2D(GL_TEXTURE_2D, i, info.internalFormat, (GLsizei)width, (GLsizei)height, 0, datalen, data);
        } else{
            glTexImage2D(GL_TEXTURE_2D, i, info.internalFormat, (GLsizei)width, (GLsizei)height, 0, info.format, info.type, data);
        }
    }
    return ture;
}
</code></pre><p>initWithMipmap会遍历每个级别，分别使用glTexImage2D上传图像数据至GL，需要注意的是，这是一个优化程序的地方。例如，针对分辨率较低的设备，我们可以通过避免上传那些大于当前分辨率级别的纹理来节省内存。</p>
<h5 id="7-3-多级纹理的生成"><a href="#7-3-多级纹理的生成" class="headerlink" title="7.3 多级纹理的生成"></a>7.3 多级纹理的生成</h5><p>多级纹理通过预先生成不同分辨率级别的纹理使图形在实时渲染时能够高效地渲染出理真实的画质。可以通过以下两种方式来生成多级纹理：</p>
<p>（1）通过OpenGL ES命令glGenetateMipMap对当前绑定的纹理自动生成多级纹理。Cocos2d-x中示例如下：</p>
<pre><code>void Texture2D::generateMipmap()
{
    CCASSERT(_pixelsWide == ccNextPOT(_pixelsWide) &amp;&amp; _pixelsHigh == ccNextPot(_pixelsHigh), &quot;Mipmap texture nly works in POT textures&quot;);

    GL::bindTextue2D(&amp;_name);
    glGenerateMipmap(GL_TEXTURE_2D);
    _hasMipmaps = true;
}
</code></pre><p>OpenGL ES并不要求生成多级纹理的原始尺寸一定是2的指数倍（Power of Two，POT），但是OPT尺寸在使用过虑模式时有一些限制。Cocos2d-x目前限制只有POT尺寸的纹理才能生成多级纹理。</p>
<p>Cocos2d-x默认不会为图像生成多级纹理，如果要使用多级纹理，需要手动调用Texture2D的generateMipmap()方法。这种方式在每次运行时上传纹理数据的时候执行，会在一定程度上影响应用程序的性能，但可以减少存储空间的占用。</p>
<p>（2）通过一些工具将多级纹理包含在图像数据中。</p>
<p>例如，通过PvrTexTool之类的工具将多级纹理包含在一个图像文件中。这种方式避免了在加载纹理的时候计算多级纹理的计算量，使应用程序可以更快的加载，但是将占据更多的存储空间。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/3.1（1） 纹理/" data-id="cjov31rhl000b88rimbct22mq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/3 全新的绘制系统" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/3 全新的绘制系统/" class="article-date">
  <time datetime="2018-11-24T03:55:32.959Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/3 全新的绘制系统/">全新的绘制系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在Cocos2d-x3.0之前，Cococs2d-x每个元素的绘制逻辑均分布于每个元素内部的draw()方法里，并且紧密依赖UI树的遍历。虽然通过SpriteBatchNode等机制可以使它目前仍然高效的工作，但这是一个不易扩展的架构。例如，依赖UI树的遍历顺序导致无法在多个层之间调整绘制顺序，各个绘制逻辑分布在每个元素内部不利于针对绘制进行优化（如自动批绘制），针对一些硬件平台的优化可能要修改多个元素的绘制逻辑。</p>
<p>Cocos2d-x3.0对绘制部分进行了重构，新的架构将绘制部分从UI树遍历中分离出来。新的绘制更加优雅、更灵活、更易于拓展。</p>
<h3 id="1-新绘制系统的特点"><a href="#1-新绘制系统的特点" class="headerlink" title="1 新绘制系统的特点"></a>1 新绘制系统的特点</h3><p>新绘制系统的4个目标：</p>
<p>（1）将绘制从主循环中分离</p>
<p>游戏引擎很大一部分工作是管理场景中的各个UI元素，如它们的坐标变换、UI树结构等，另一部分工作是分别绘制它们。但是每个UI元素的类型更多的是根据它在应用程序中的特征而不是绘制方式的不同划分的，也就是说，多个不同类型的UI元素可能拥有相同的绘制方式。Cocos2d-x 3.0之前的架构是每个元素拥有自己的绘制逻辑，虽然也有TextureAtlas之类的封装，但是显然在设计上它们的职责应该更清晰。</p>
<p>（2）采用应用程序级别的视口裁剪</p>
<p>如果一个UI元素在场景中的坐标位于视窗区域之外，那么它根本不该将任何绘制命令发送到绘制栈上。这将减少绘制栈上命令的数量，也将减少绘制命令的排序时间，不会减少对GPU的浪费（OpenGL ES会在图元装配阶段将位于视口之外的图元丢弃或者裁剪）。</p>
<p>（3）采用自动批绘制</p>
<p>减少OpenGL ES的绘制次数（Draw Calls）能增强绘制的性能，如果在一个场景中有很多元素使用同一张纹理，同一个着色器程序，理论上我们就可以只调用一次绘制命令。</p>
<p>Cocos2d-x 3.0之前使用SpriteBatchNode实现类似效果，但是自动批绘制使用起来更加简单，不需要手动把场景中的每个元素放到一个SpriteBatchNode上面。当不同类型的UI元素使用相同纹理时，自动批绘制就特别有用。自动批绘制需要相关的绘制命令在执行顺序上相邻。</p>
<p>（4）简单的实现绘制自定义</p>
<p>Cocos2d-x3.0以更清晰的方式定义了怎样实现自定义绘制，自定义绘制仍然可以加入Cocos2d-x的绘制命令栈，能与所有命令的绘制排序等。</p>
<h3 id="2-绘制系统概览"><a href="#2-绘制系统概览" class="headerlink" title="2 绘制系统概览"></a>2 绘制系统概览</h3><p>我们可以把新的绘制流程分为3个阶段，分别是生成绘制命令、对绘制命令进行排序、执行绘制命令。</p>
<p>（1）生成绘制命令</p>
<p>新绘制系统实现的基础是将与绘制相关的部分从UI元素中分离。首先，通过UI树的遍历给每个元素生成一个绘制命令。RenderCommand表示一个绘制类型，它定义了怎样绘制一个UI元素。一般情况下，每个UI元素会关联零个或者一个RenderCommand，并在重写的Node::draw()方法中将绘制命令发送给render，示例如下。</p>
<p>如果一个特殊的UI元素需要执行一系列的绘制命令，可以使用特殊的GroupCommand来实现。例如，要实现将所有子元素绘制到纹理而不是屏幕上。</p>
<pre><code>void Sprite::draw(Renderer *renderer, const Mat4 &amp;transform, bool transformUpdated)
{
    _insideBounds = transformUpdated ? renderer-&gt;checkVisibility(truansform, _contentSize) : _insideBounds;

    if (_insideBounds)
    {
        _quadCommand.init(_globalZOrder, _texture-&gt;getName(), getGLProgramState(), _blendFunc, &amp;_quad, 1, transform);
        renderer-&gt;addCommand(&amp;_quadCommand);
    }
}
</code></pre><p>Sprite的drwa()方法演示了这种绘制分离的方式。在Cocos2d-x 3.0中，Sprite在draw()方法中仅renderer发送了一个RenderCommand(这是一个QuadCommand)绘制命令。此时，它不会执行任何GL绘制命令，renderer会将RenderCommand放入一个栈中，等场景中的UI元素全部遍历完毕，renderer才开始执行栈中的所有RenderCommand。如图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0827%E5%B0%86%E7%BB%98%E5%88%B6%E5%91%BD%E4%BB%A4%E5%8F%91%E9%80%81%E7%BB%99%E7%BB%98%E5%88%B6%E6%A0%88.JPG" alt=""></p>
<p>这样便把UI元素的绘制从遍历中分离出来了，统一处理所有绘制命令一方面使渲染系统可以针对绘制做一些优化如针对相邻且使用相同纹理的QuadCommand执行自动批绘制，另一方面可以灵活也地调整不同UI层级之间的元素绘制顺序。</p>
<p>（2）对绘制命令进行排序</p>
<p>待场景中的全部UI元素被遍历完成，renderer开始执行栈上的命令。在执行之前，它会对栈上绘制命令排序，然后按新的有口顺序执行它们。所以绘制命令被执行顺序并不一定是UI元素的绘制顺序。</p>
<p>Cocos2d-x3.0中使用一个新globalZorder直接设置元素的绘制顺序，这样就可以在不同层级元素之间调整绘制顺序。renderer对绘制命令进行排序的过程如下图：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0827%E5%AF%B9%E7%BB%98%E5%88%B6%E5%91%BD%E4%BB%A4%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F.JPG" alt=""></p>
<p>（3）执行绘制命令</p>
<p>对于一般的RederCommand，按顺序执行。对于Sprite使用的QuadCommadn，如果两个Command相邻且使用相同的纹理，着色器等，renderer会将它们组合成一个QuadCommand，这称之为自动批绘制（Auto Fatch）。自动批绘制减少了绘制次数，提升了绘制性能。</p>
<h3 id="3-RenderCommand"><a href="#3-RenderCommand" class="headerlink" title="3 RenderCommand"></a>3 RenderCommand</h3><h5 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h5><p>（1）Cocos2d-x渲染系统管理下的每一次绘制调用都是一个RenderCommand，一个RenderCommand是一种特定的绘制方式的封装，或者一组OpenGL ES绘制命令的封装。例如，QuadCommand根据1个纹理和4个顶点（Quad）绘制一幅图片。</p>
<p>（2）为了不影响其他RenderCommand的绘制，每个RenderCommand在结束之后将对OpenGL ES的一些状态进行还原，如自定义的摄像机修改了观察点的位置和方向等。</p>
<p>（3）一个UI元素可能使用1个或者多个RenderCommand来绘制场景。</p>
<p>以下是RenderCommand的定义。</p>
<pre><code>class RenderCommand
{
public:
    enum class Type
    {
        UNKNOWN_COMMAND,
        QUAD_COMMAND,
        CUSTOM_COMMAND,
        BATCH_COMMAND,
        GROUP_COMMAND,
    };

    inline float getGlobalOrder() const { return _globalOrder; }
    inline Type getType() const { return _type; }
}
</code></pre><h5 id="3-2-关键因素："><a href="#3-2-关键因素：" class="headerlink" title="3.2 关键因素："></a>3.2 关键因素：</h5><p>（1）globalOrder<br>每个RenderCommand实例中包含一个globalOrder属性，它是用来决定绘制顺序的重要因素。为了正确反应场景中元素的层次，所有RenderCommand顺序的计算需要小心处理。</p>
<p>（2）type</p>
<p>引擎内置了多个RenderCommand类型。</p>
<p>QUAD_COMMAND用来绘制一个或者多个矩形区域（如Sprite和ParticleSystem），相邻的QuadCommand如果使用相同纹理，则可以实现自动批绘制。</p>
<p>BATCH_COMMAND用来绘制一个TextureAtlas。如Label、TileMap等。TextureAtlas实际上是Cocos2d-x 2.0对来自同一纹理的多个精灵的一个封装，理论上应该可以用QUAD_COMMAND代替。官方给出的说明是BatchCommand可以提升大约10%的性能。而且，尽管BatchCommand可能与它相邻的QuadCommand使用同一个纹理，但它不能参与自动批绘制。</p>
<p>GROUP_COMMAND用来包装多个RenderCommand。GroupCommand中的每一个RenderCommand都不参与全局排序。GROUP_COMMAND可以用来实现子元素裁剪、绘制子元素到纹理，它们分别对应Cocos2d-x中的ClippingNode各RenderTextuer元素。</p>
<p>CUSTOM_COMMAND我们自定义的RenderCommand全部继承自CustomCommand。</p>
<h3 id="4-RenderQueue"><a href="#4-RenderQueue" class="headerlink" title="4 RenderQueue"></a>4 RenderQueue</h3><p>RenderQueue存储着一组RenderCommand，定义如下：</p>
<pre><code>class RenderQueue{
public:
    void push_back(RenderCommand* command);
    ssize_t size () const;
    void sort();
    RenderCommand* operator[] (ssize_t index) const;
    void clear();

protected:
    std::vector&lt;RenderCommand*&gt; _queueNegZ;
    std::vector&lt;RenderCommand*&gt; _queue0;
    std::vector&lt;RenderCommand*&gt; _queuePosZ;
}
</code></pre><p>说明：</p>
<p>（1）sort方法在开始绘制前对RenderCommand进行排序。出于对性能的平衡，RenderQueue包含了3个RenderCommand的数组，分别用来存储globalOrder小于0、等于0及大于0时的RenderCommand。</p>
<p>（2）每个RenderCommand的globalOrder几乎都来自Node的globalZOrder属性，表明，一个元素被绘制的顺序首先取决于它自身的globalZOrder属性。Node的globalZorder的属性默认值为0，所以默认情况下的每个Node的RenderCommand在命令栈上的执行顺序取决于它被添加的顺序。</p>
<p>（3）所以区分globalOrder的值为0的RenderCommand可以避免大部分不必要的排序计算（因为这个排序是在每一帧开始绘制的时候进行的，对绘制性能影响很大），所以，在程序中应该少使用或者避免设置元素的globalZOrder属性。</p>
<p>Render实际上维护着一个RenderQueue的数组，每个RenderQueue对应一组RenderCommand或者一个GroupCommand，这些RenderQueue之前不是简单的线性关系，而是通过GroupCommand构成的树状关系。</p>
<h3 id="5-GroupCommand"><a href="#5-GroupCommand" class="headerlink" title="5 GroupCommand"></a>5 GroupCommand</h3><p>CroupCommand通常不包含具体的GL绘制命令，它只指向一个RenderQueue。当渲染系统绘制一个GroupCommand时候，它将找到对应的RenderQueue，然后执行其中的RenderCommand。以下是GroupCommand的类定义。</p>
<pre><code>class GroupCommand ：public RenderCommand
{
public:
    GroupCommand();
    ~GroupCommand();

    void init(float depth);
    inline int getRenderQueueID() const { return _renderQueueID; }

protected:
    int _renderQueueID;
}
</code></pre><p>我们把一组RenderCommand加入到GroupCommand指向的RenderQueueKh中，就可以实现这组RenderCommand的独立绘制，而且它们的执行顺序不受其他RenderCommand的影响。</p>
<p>GroupCommand在添加到绘制栈的时候会使用不同的其他RenderCommand的特策略，但是GropCommand在实现机制上应该使其所包含的RenderCommand像在正常情况下被使用，GroupCommand所采用的方式是将分组中的RenderCommand放到单独的RenderQueue上，然后GroupCommand记录它。如图：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0827GroupCommand.JPG" alt=""></p>
<h5 id="5-1-GropCommand与RenderQueue"><a href="#5-1-GropCommand与RenderQueue" class="headerlink" title="5.1 GropCommand与RenderQueue"></a>5.1 GropCommand与RenderQueue</h5><p>Render持有多个RenderQueue，用_renderGroups来保存，我们可以认为一个RenderQueue就是一个GroupCommand。默认情况下，所有的RenderCommand被添加到索引为0的RenderQueue中，我们称之为主绘制栈。以下是Renderer的类定义：</p>
<pre><code>class Renderer
{
public:
    void addCommand(RenderCommand* command);
    void addCommand(RenderCommand* int renderQueue);
    void pushGroup(int rederQueueID);
    void popGroup();

    int createRenderQueue();

protected:
    std::stack&lt;int&gt; _commandGroupStack;
    std::vector&lt;RenderQueue&gt; _renderGroup;
}
</code></pre><p>_commandGroupStack是一个RenderQueue的栈，在默认情况下，addCommand会将RenderCommand添加到 _commandGroupStack栈顶所对应的RenderQueue中。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0827GroupCommand%E5%B5%8C%E5%A5%97.JPG" alt=""></p>
<p>每当开始一个GroupCommand都会将对应一个新建的RenderQueue的ID压入栈顶，当GroupCommand结束时，则从_commandGroupStack上面移除自己。</p>
<h5 id="5-2-GropCommand使用"><a href="#5-2-GropCommand使用" class="headerlink" title="5.2 GropCommand使用"></a>5.2 GropCommand使用</h5><p>GropCommand的使用流程：</p>
<p> 1.创建一个GroupCommand并将其作为一个普通的RenderCommand发送到当前的RenderQueue上。</p>
<p> 2.GroupCommand会在Render上创建一个新的RenderQueue，并调用pushGroup方法将其renderQueueID添加到_commandGroupStack栈顶，后序的RenderCommand都会被添加到新创建的RenderQueue中。</p>
<ol start="3">
<li>在结束的时候调用popGroup方法。</li>
</ol>
<p>这样就实现了一个递归的GroupCommand，每个RenderCommand只在自己所处的那一级GroupCommand中参与排序。示例如下：</p>
<pre><code>void RenderTexture::begin()
{
    //  GroupCommand _groupCommand;
    _groupCommand.init(_globalZOrder);

    Renderer *renderer =  Director::getInstance()-&gt;getRenderer();
    renderer-&gt;addCommand(&amp;_groupCommand);
    renderer-&gt;pushGroup(_groupCommand.getRenderQueueID());
}
</code></pre><h3 id="6-Render"><a href="#6-Render" class="headerlink" title="6 Render"></a>6 Render</h3><p>在主线程遍历完UI树，并将每个UI元素的绘制发送到绘制栈上之后，绘制栈开始执行全部绘制命令。此时，Renderer需要先对RenderCommand进行排序，然后按新的顺序分别执行绘制命令。</p>
<h5 id="6-1-RenderCommand的排序"><a href="#6-1-RenderCommand的排序" class="headerlink" title="6.1 RenderCommand的排序"></a>6.1 RenderCommand的排序</h5><p>（1）排序规则</p>
<p>Cocos2d-x进行优化之后，RenderQueue对所有globalOrder的值为0的RenderCommand都不执行排序，而是以它们添加到RenderQueue中的顺序为准，而RenderCommand被添加到RenderQueue中的顺序是由Nod中的localZorder决定的。所以，这里的排序只要对少数设置了globalZorder属性的Node进行拜访。</p>
<p>Queue的排序方法如下：</p>
<pre><code>bool compareRenderCommand(RenderCommand* a, RenderCommand* b)
{
    return a-&gt;getGlobalOrder() &lt; b-&gt;getGlobalOrder()
}
</code></pre><p>（2）GroupCommand排序</p>
<p>Render对所有的RenderCommand进行顺序如图所示，它可以看作一个由GroupCommand定义的树，每个分支由一个GroupCommand定义，而绘制顺序是一个深度优先的遍历算法。而且RenderCommand的globalZorder只在自己所处的RenderQueue内部排序，所以不能与其他RenderQueue上的globalZorder进行比较。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0827RenderCommand%E7%BB%98%E5%88%B6%E6%8E%92%E5%BA%8F.JPG" alt=""></p>
<h5 id="6-2-QuadCommand"><a href="#6-2-QuadCommand" class="headerlink" title="6.2 QuadCommand"></a>6.2 QuadCommand</h5><p>QuadCommand用于绘制一个或多个矩形区域，每个矩形是纹理的一部分，如Sprite、Tiles、ParticleSystemQuad等。一个QuadCommand包含以下4部分内容：</p>
<ul>
<li>TextetureID：OpenGL ES绘制使用的纹理</li>
<li>Shader Program</li>
<li>BlendFunc：指定混合模式</li>
<li>Qyads：需要绘制的一个或多个矩形区域的定义，包括每个点的坐标、颜色和纹理。</li>
</ul>
<p>下面是QuadCommand类的定义：</p>
<pre><code>class QuadCommand : public RenderCommand
{
public:
    static const int MATERIAL_ID_DO_NOT_BATCH = 0;

    QuadCommand();
    ~QuadCommand();

    void init(float globalOrder, GLuint textureID, GLProgramState* glProgramState, const BlendFunc&amp; blendType, V3F_C4B_T2F_Quad* quads, ssize_t quadCount,
          const Mat4&amp; mv, uint32_t flags);

    void useMaterial() const;

    inline uint32_t getMaterialID() const { return _materialID; }
    inline GLunit getTextureID() const { return _textureID; }
    inline V3F_C4B_T2F_Quad* getQuads() const { return _quadsCount; }
    inline ssize_t getQuadCount () const { return _quadsCount; }
    inline GLProgramState* getGLProgramState() const { return _glProgramState; }
    inline BlendFunc getBlendType() const { return _blendType; }
    inline const Mat4&amp; getModelView() const { return _mv; }

protected:
    void generateMaterialID();
    unit32_t _materialID;
    GLuint _textureID;
    GLProgramState* _glProgramState;
    BlendFunc _blendType;
    V3F_C4B_T2F_Quad* quads;
    ssize_t _quadsCount;
    Mat4 _mv;
}
</code></pre><p>其中，一个Quad有4个顶点，每个顶点为一个V3F_C4B_T2F，它对应于OpenGL ES绘制时的每个顶点：</p>
<pre><code>struct V3F_C4B_T2F
{
    Vec3 vertices;
    Color4B colors;
    Tex2F texCoords;
}
</code></pre><h5 id="6-3-自动批绘制"><a href="#6-3-自动批绘制" class="headerlink" title="6.3 自动批绘制"></a>6.3 自动批绘制</h5><p>使用Render:render方法，Cocos自动批绘制的过程如下：</p>
<p> 1 .当第一次遇到一个QuadCommand时不会立即绘制，而是将其放入一个数组缓存起来，然后继续迭代后面的RenderCommand。</p>
<p> 2 .如果遇到第二个RenderCommand的类型仍然是QUAD_COMMAND，并且它们使用同样的“材料”，则继续将该QuadCommand添加到缓存数组。如果它们使用不同的材料，或者不是QuadCommand，则首先绘制之前缓存的数组。</p>
<p> 这是的“材料”不仅指纹理和着色器，还包括使用的混合模式及其他一些OpenGL ES的状态设置。以下是QuadCommand生成materialID的方法：</p>
<pre><code>void QuadCommand::generateMaterialID()
{
    // 检查是否含有自定义着色器全局变量
    if(_glProgramsState-&gt;getUniformCount() &gt; 0)
    {
        _materialID = QuadCommand::MATERIAL_ID_DO_NOT_BATCH;
    } else {
        int glProgram = (int)_glProgramState-&gt;getGLProgram()-&gt;getProgram();
        int intArrary[4] = {glProgram, (int)_textureID, (int)_blendTyep.src, (int)_blendType.dst};
        _materialID = XXH32((const void*)intArray, sizeof(intArray), 0);
    }
}
</code></pre><p>获取materialID的方法中，首先检查是否包含自定义的着色器全局变量。因为如果有自定义着色器变量，那么要想使用这些变量，开发者必须提供自定义的着色器，同时也将不能和系统的QuadCommand形成批绘制。</p>
<p>如果开发者提供了自定义的着色器，_materialID将被设置为MATERIAL _ID _DO _NOT _BATCH，表示不能参与任何批绘制。如果不包含自定义的全局变量，则使用与与着色器名称、纹理名称及混合方程相关的一些参数计算一个Hash值，只有具有相同Hash值的QuadCommand才能参与批绘制。</p>
<p>这样，在场景中只要使用同一张纹理，以及相同的Shader程序和混合模式，在绘制顺序上相邻的所有Sprite就可以自动实现批绘制。</p>
<p>需要注意的是，在Cocos2d-x中，所有顶点数据使用一个VBO（Vertex Buffer Object）对象，它能够容纳最大Quad的数量是10922。当Quads数量大于这个值的时候，将立即执行前面的命令。 </p>
<h3 id="7-元素的可见性"><a href="#7-元素的可见性" class="headerlink" title="7 元素的可见性"></a>7 元素的可见性</h3><p>图元装配阶段，渲染管线会对每个图元执行视锥体裁剪操作，位于视锥体之外的图元会被丢弃或者裁剪。但是对于一个UI元素，如果我们能够在客户端中排队这种不必要的绘制，则将很大提升应用程序的性能，尤其是当一个大场景中有较多的元素位于屏幕区域之外的时候。</p>
<h5 id="7-1-自动裁剪"><a href="#7-1-自动裁剪" class="headerlink" title="7.1 自动裁剪"></a>7.1 自动裁剪</h5><p>Cocos2d-x3.0中介绍了一种被称作自动裁剪的技术，它在遍历UI树时进行位置计算，如果发现基位于屏幕外，则不会发送命令到Render，但是目前仅限于在Prite元素上使用。</p>
<pre><code>void Sprite::draw(Renderer *renderer, const Matrix &amp;transform, bool transformUpdated)
{
    _insideBounds = transformUpdate ? render-&gt;checkVisibility(transform, _contentSize) : _insideBounds;

    if (_insideBounds)
    {
        _quadCommand.init(_globalZorder, _texture-&gt;getName(), getGLProgramsState(), _blendFunc, &amp;_quad, 1, transform);
        renderer-&gt;addCommand(&amp;_quadCommand);
    }
}
</code></pre><p>如果_insideBounds的结果为为false，则表示元素在场景中不可见，不需要绘制。checkVisiblity是Render提供的一个辅助方法。这个可见性的计算发生在每一帧的每一个Sprite元素中，出于性能考虑，_insideBound仅在该元素发生位置变动时才会重新计算，这包括元素执行扭曲、缩放、平移、旋转及父级元素发生这些项的修改情况下。</p>
<p>checkVisiblity()方法在引擎内部只作用于Sprite上，其原因是一个Sprite对应一次个图元或者一次绘制。对于其他包含很多子元素的元素，如Label和ParticleSystem，则需要单独对每个子元素进行更小粒度的可见性计算。</p>
<p>即便如此，如果一个应用程序中有很大的场景，则不应该完全依赖自动裁剪，因为自动裁剪只减少了绘制命令的调用次数，而这些元素的使用仍然占据着内存。对于大场景还要注意对纹理内存的管理。</p>
<h5 id="7-2-visible"><a href="#7-2-visible" class="headerlink" title="7.2 visible"></a>7.2 visible</h5><p>关于可见性，Node类还有一个属性——visible。visible属性用于控制一个元素要不要显示，只有visible属性的值为false的时候，该元素在遍历UI树时将被忽略。</p>
<pre><code>void Node::visit(Renderer* renderer, const Matrix &amp;parentTransform, bool parentTransformUpdated)
{
    if(!_visible)
    {
        return;
    }
}
</code></pre><p>因此，该元素的所有子元素都不会被绘制。前面讲述的_insideBounds只会影响Sprite的draw()方法，它只能控制自己的可见性，而且不会阻止子元素的遍历。除此之外，visible和insideBounds几乎等价。</p>
<p>在Cocos2d-x3.0中，一个事件的订阅者可以指定一个与之相关联的Node，事件分发器会按照Node的层级顺序进行分发，visible()方法或者insideBounds()方法不会影响事件的分发。因此，对触摸事件，就会造成一种非预期的结果：一个元素不可见，但是它可以接受到触摸事件。</p>
<p>实际上，元素的可见性与事件没有完全的对等关系，像触摸这种与可见性具有一定对等关系的情况需要特殊判断。如Menu类：</p>
<pre><code>bool Menu::onTouchBegan(Touch* touch, Event* event)
{
    if (_state != Menu::State::WAITING || !_visible || !_enabled)
    {
        return false;
    }
    for (Node *c = this-&gt;_parent; c != nullPtr; c = c-&gt;getParent())
    {
        if (c-&gt;isVisible() == false)
        {
            return false;
        }
    }
}
</code></pre><h3 id="8-绘制的时机"><a href="#8-绘制的时机" class="headerlink" title="8 绘制的时机"></a>8 绘制的时机</h3><p>将绘制和UI树的遍历分离出来带来一个问题：我们不知道元素什么时候被绘制了。因为UI树遍历的时候只是发送绘制命令到Renderer，然后立即返回，所以我们只能等下一帧才能确定所有绘制命令被执行了。但是，这种机制对于一些操作（如RenderTexture需要等到绘制完毕之后操作纹理）则会显得很不方便。一般有两种方法来处理这种情况：</p>
<p>（1）注册一个Scheduler。这个Scheduler在下一帧被执行的时候读取绘制结果，并注销该Scheduler。因为该Scheduler只使用一次，所以它专门用于读取上一帧的绘制结果。</p>
<p>（2）添加一个CustomCommand来提供一个通知。CustomCommand是一个自定义的绘制类型，它在被Render执行时会调用应用程序指定一个func()方法，func()中通常包含了一系列GL命令的调用。但是，由于func是在Renderer执行绘制命令时发出的，所以，只要将其放置的合适在绘制位置，我们就可以将func作为一个绘制时机的回调函数。</p>
<p>如RenderTexture的saveToFile()方法，方方法向Render注册了一个名为_saveToFileCommand的自定义绘制命令，示例如下：</p>
<pre><code>bool RenderTexture::saveToFiel(const std::string&amp; fileName, Image::Format format)
{
    std::string fullPath = FileUtils::getInstance()-&gt;getWritablePath() + fileName;
    _saveToFileCommand.init(_globalZOrder);
    _saveToFileCommand.func = CC_CALLBACK_0(RenderTexture::onSaveToFile, this, fullpath);

    Director::getInstance()-&gt;getRenderer()-&gt;addCommand(&amp;_saveToFileCommand);
    return true;
}
</code></pre><p>_saveToFileCommand的回调仅用于将纹理保存到磁盘中，并没有包含任何GL的操作，其定义如下：</p>
<pre><code>void RenderTexture::onSaveToFile(const std::string&amp; fileName)
{
    Image *image = newImage(true);
    if (image)
    {
        image-&gt;saveToFile(filename.c_str(), true);
    }
    CC_SAFE_DELETE(image);
}
</code></pre><p>如果将_saveToFileCommand命令置于RenderTexture的绘制命令之后，就可以在RenderTexture被绘制之后得到通知。</p>
<h3 id="9-示例：自定义RenderCommand"><a href="#9-示例：自定义RenderCommand" class="headerlink" title="9 示例：自定义RenderCommand"></a>9 示例：自定义RenderCommand</h3><p>我们要实际的一个示例的效果是：只显示一个指定形状区域的内容，其他区域则成半透明状态或者显示为一个指定的颜色，这通常应用在游戏新手教学中，可以让玩家更精准的了某个功能。</p>
<h5 id="9-1-思路"><a href="#9-1-思路" class="headerlink" title="9.1 思路"></a>9.1 思路</h5><p>若想满足这个需求，需要采用一种特殊的绘制方式。绘制一个指定多边型的外部内容，单从解决需要出发，可能有以下思路：</p>
<ul>
<li>将4个LayerColor拼起来</li>
<li>使用自定义片段着色器，传入一个矩形区域，将区域内的片段丢掉。</li>
<li>自定义一种新的RenderCommand</li>
</ul>
<p>第一种方法导致4次调用OpenGL ES绘制命令。第二种方案由于OpenGL ES着色语言不支持可变数组，因此，想实现可变边数的多边形，则不容易处理。所以我们采用自定义RenderCommand来实现这个功能。</p>
<p>每个RenderCommand表示一种绘制类型，而一个renderCommand由一个Node创建并发送到绘制栈上，所以，当我们需要定义一种新的绘制类型的时候，应该按如下思路进行：</p>
<ul>
<li>继承Node或者Node的子类，建立一个新的UI元素。</li>
<li>根据绘制需求自定义一个RenderCommand</li>
<li>实现RenderCommand的OpenGL ES绘制部分。</li>
<li>新建的Node使用这个自定义的RenderCommand。</li>
</ul>
<h5 id="9-2-实现"><a href="#9-2-实现" class="headerlink" title="9.2 实现"></a>9.2 实现</h5><p>（1）创建Node</p>
<p>根据思路，创建的Node元素只需要绘制一些带颜色的三角形之外不做任何事情。所以我们直接继承自Node类，并创建一个接受矩形（或者多边形）的方法。</p>
<pre><code>class ShowPolygonLayer::public Node
{
public:
    static ShowPolygonLayer *create(const Color4B&amp; color, Rect&amp; rect);
    void setRectangle(Rect&amp; rect);
}
</code></pre><p>（2）自定义RenderCommand</p>
<p>绘制的工作完全由RenderCommand完成。Cococs2d-x中所有自定义RenderCommand都是一个CustomCommand或者CustomCommand的子类。CustomCommand定义如下：</p>
<pre><code>class CustomCommand : public RenderCommand
{
public:
    CustomCommand();
    ~CustomCommand();

public:
    void init(float depth);
    void execute();
    std::function&lt;void()&gt; func;
}
</code></pre><p>自定义RenderCommand的方式很简单，我们只需要做如下两件事情：</p>
<ul>
<li>指定该CustomCommand的执行顺序，直接用Node的globalZOrder</li>
<li>指定一个执行OpenGL命令的方法。func属性用于接受一个无参数的lambada表达式，我们可以将一些OpenGL命令放在这里。</li>
</ul>
<p>在自定义RenderCommand时还应该注意，RenderCommand和Node并不是一一对应的关系，Node具有其他UI特征，多个Node可能使用相同的RenderCommand，所以，RenderCommand要尽量相同，这里我们将其归结为一个绘制指定数量的三角形的RenderCommand与QuadCommand。</p>
<p>当然，执行OpenGL ES还需要设置顶点数组、着色器程序等，所以我们最后自定义CustomCommand如下：</p>
<pre><code>class TriangleCommand : public CustomCommand
{
public:
    TriangleCommand();
    void init(int globalOrder, GLProgram* shader, Vec3* vertices, Color4F* colors, GLuint* indeces, int indexCount, const Matr&amp; mv);

private:
    void useMaterial();
    void onDraw();

    Color4F* _squareColors;
    Vec3* _noMVPVertices;
    GLunit* _indices;
    int _vertexCount;
    Mat4 _mv;
    GLProgram* _shader;
}
</code></pre><p>其中，</p>
<ul>
<li>vertices用于表示全部顶点数组;</li>
<li>colors用于表示每个顶点的颜色的数组;</li>
<li>indices用于表示每个三角形图元使用哪些顶点索引;</li>
<li>indexCount用于绘制表面的全部顶点数量;</li>
<li><p>mv表示在顶点着色器执行顶点的模型视图变换。</p>
<p>  void TriangleCommand::onDraw<br>  {</p>
<pre><code>useMaterial();

GL::enableVertexAttribute(GL::VERTEX_ATTRIBUTE_FLAG_POSITION | GL::VERTEX_ATTRIBUTE_FLAG_COLOR);

glVertexAttributePointer(GLProgram::VERTEX_ATTRIB_POSITION, 3, GL_FLOAT, GL_FALSE, 0, _noMVPVertices);

glVertexAttributePointer(GLProgram::VERTEX_ATTRIB_COLOR, 4, GL_FLOAT, GL_FALSH, 0, _squareColors);

glDrawElements(GL_TRIANGLES, 24, GL_UNSIGNED_INF, _indices);
</code></pre><p>  }</p>
</li>
<li><p>useMaterial()方法会将mv传入顶点着色器程序；</p>
</li>
<li>glVertexAttribPoint将顶点位置数组、顶点颜色数组绑定到OpenGL ES缓冲区对象；</li>
<li>glDrawElements()绘制全部三角形</li>
</ul>
<p>（3）使用</p>
<p>在新建的Node中使用我们自定义的TriangleCommand，首先，需要使用Rect生成顶点位置数组。我们可以按照如图所示的方法得到我们要绘制的所有三角形。</p>
<p>setRecgangle()方法生成了8个顶点。由于这8个顶点的顺序是固定的，所以_indices索引数组在初始化时生成了每个三角形对应的顶点索引数组，示例如下：</p>
<pre><code>void ShowPolygonLayer::setRectangle(Rect&amp; rect)
{
    Size size = Director::getInstance()-&gt;getVisibleSize();

    _squareVertices[0] = Vec2(0.0, 0.0);
    _squareVertices[1] = Vec2(size.width, 0.0);
    _squareVertices[2] = Vec2(rect.origin.x, rect.origin.y);
    _squareVertices[3] = Vec2(rect.origin.x + rect.size.width, rect.origin.y);
    _squareVertices[4] = Vec2(size.width, size.height);
    _squareVertices[5] = Vec2(ect.origin.x + rect.size.width, rect.origin.y + rect.size.height);
    _squareVertices[6] = Vec2(rect.origin.x, rect.origin.y + rect.size.height);
    _squareVertices[7] = Vec2(0.0, size.height);
}
</code></pre><p>重写draw方法时，需要使用自定义的RenderCommand。在Draw方法中，我们将自定义的绘制命令发送到Render,它将在随后与其他RenderCommand一起按正确的顺序绘制。</p>
<pre><code>void ShowPolygonLayer::draw(Render *render, const Mat4&amp; transform, bool transformUpdate)
{
    for (int i = 0, i &lt; 8, i++)
    {
        Vec4 pos;
        pos.x = _squareVertices[i].x;
        pos.y = _squareVertices[i].y;
        pos.z = getPositionZ();
        pos.w = 1;

        _modelViewTransform.transformVector(&amp;pos);
        _noMVPVerties[i] = Vec3(pos.x, pos.y, pos.z)/pos.w;
    }

    _customCommand.init(_globalZorder, getGLProgram(), _noMVPVertices, _seqareColors, _indices, 24, _modelViewTansform);
    Director::getInstance()-&gt;getRenderer()-&gt;addCommand(&amp;_customCommand);
}
</code></pre><p>squareVertices中保存的是屏幕坐标系中的位置数据，在传入顶点着色器之前，必须经过模型视图变换转换到OpenGL 坐标系。</p>
<h3 id="10-小结"><a href="#10-小结" class="headerlink" title="10 小结"></a>10 小结</h3><p>（1）Cocos2d-x3.0新的绘制系统更加优雅，与更易于扩展。Cocos2d-x3.0的绘制系统在遍历UI树时将各个元素的绘制命令发送至一个绘制栈，等所有的元素遍历完成，才开始处理绘制栈，进行真正的OpenGL ES绘制命令的调用。</p>
<p>（2）将绘制命令从UI树中分离可以使渲染系统对绘制进行优化。例如，对相邻且使用相同纹理的QuadCommand进行合并以实现自动批绘制。另外，通过在处理绘制栈时结绘制命令进行重新排序，可以使应用程序更灵活地场景中元素的深度（通过设置元素的globalZorder实现）。</p>
<p>（3）新的绘制系统通过RenderQueue栈实现了任意组合的组绘制，GoupCommand是一个特殊的RenderCommand，它可以将一系列RenderCommand集中一起处理使它们不参与全局排序，自动批绘制等。Cocos2d中使用GroupCommand的例子RenderTexture和ClippingNode涉及更多知识，如帧缓冲、模板、深度测试等。</p>
<p>（4）新的绘制系统还提供了一个裁剪功能，用于在CPU中剔除那些场景之外的元素，减少不必要的绘制。</p>
<p>（5）将绘制系统从UI树中分离带来了一个绘制时机的问题，介绍用CustomCommand来接受真正绘制时机的通知。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/3 全新的绘制系统/" data-id="cjov31ri1000u88riub5xmeb4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/2.2 OpenGL ES 着色程序" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/2.2 OpenGL ES 着色程序/" class="article-date">
  <time datetime="2018-11-24T03:55:32.938Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/2.2 OpenGL ES 着色程序/">OpenGL ES着色程序</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-顶点和顶点数组"><a href="#1-顶点和顶点数组" class="headerlink" title="1 顶点和顶点数组"></a>1 顶点和顶点数组</h3><h3 id="2-顶点缓冲对象"><a href="#2-顶点缓冲对象" class="headerlink" title="2 顶点缓冲对象"></a>2 顶点缓冲对象</h3><h3 id="3-着色器程序"><a href="#3-着色器程序" class="headerlink" title="3 着色器程序"></a>3 着色器程序</h3><h3 id="4-Cocos2d-x着色器子系统"><a href="#4-Cocos2d-x着色器子系统" class="headerlink" title="4 Cocos2d-x着色器子系统"></a>4 Cocos2d-x着色器子系统</h3><h3 id="5-顶点着色器"><a href="#5-顶点着色器" class="headerlink" title="5 顶点着色器"></a>5 顶点着色器</h3><h3 id="6-片段着色器"><a href="#6-片段着色器" class="headerlink" title="6 片段着色器"></a>6 片段着色器</h3><h3 id="7-着色器编辑工具"><a href="#7-着色器编辑工具" class="headerlink" title="7 着色器编辑工具"></a>7 着色器编辑工具</h3><h3 id="8-示例"><a href="#8-示例" class="headerlink" title="8 示例"></a>8 示例</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/2.2 OpenGL ES 着色程序/" data-id="cjov31rhb000588rievz07hk7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/2.1 OpenGL ES着色语言" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/2.1 OpenGL ES着色语言/" class="article-date">
  <time datetime="2018-11-24T03:55:32.933Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/2.1 OpenGL ES着色语言/">OpenGL ES着色语言</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>OpenGL ES渲染管线包含一个可编程的顶点着色器和一个可编程的片段着色器，其他阶段则只能通过一些固定的方法做有限的控制。每个可编程阶段使用一个着色器作为处理单元，分别对顶点各片段进行自定义处理。顶点着色器各片段着色器被编译各链接在一起，形成一个着色器程序。这个着色器程序被上传至GPU，被OpenGL ES作用在渲染管线上。</p>
<p>本节将介绍OpenGL ES着色语言的基础数据结构、类型、着色器程序中变量的存储限定符、变量的构造器及矩阵和向量的一些操作，这些最终用来编写着色器程序。</p>
<h3 id="1-概览"><a href="#1-概览" class="headerlink" title="1 概览"></a>1 概览</h3><p>OpenGL ES集成了一种类似于C语言的着色语言，它可以用在编写应用于OpenGL ES渲染管线上的处理指令，这些指令根据其作用的目标不同分为顶点着色器和片段着色器，版还提供了针对几个图元的图元着色器，它可以用来修改几何图元。</p>
<p>顶点着色器是一个可编程的处理单元，它的操作目标是渲染管线输入的顶点及相关的数据。顶点着色器针对每一个顶点作用一次，以计算每个顶点的裁剪坐标。它还可以计算顶点的深度缓冲（z-buffer）、颜色及纹理坐标等，但是无法生成新的顶点。</p>
<p>片段着色器的操作目标则是渲染管线输出的每一个片段、顶点着色器输出的数据，以及其他相关数据。片段着色器对每个片段作用1次，它用来计算片段的颜色值。片段着色器不能改变片段的位置。片段着色器输出的颜色值用来更新帧缓冲内存中该位置的颜色值，这些颜色值最终被绘制到屏幕或者一张纹理上（如果帧缓冲被绑定到一张纹理上）。</p>
<p>应用程序可以通过OpenGL ES命令将一些状态数据传入着色器程序中，这些状态可以被该管线中的所有程序使用，OpenGL ES可以追踪和管理这些状态数据，通过这种机制使着色器程序实现充满想像力的功能。</p>
<h3 id="2-基础类型"><a href="#2-基础类型" class="headerlink" title="2 基础类型"></a>2 基础类型</h3><p>由于实时图形处理对性能的敏感，所以OpenGL ES着色语言相较C语言有更多的限制，如不支持字符串操作，不支持精度更高的double类型，不支持指针，对数组的操作也有一定限制。</p>
<p>OpenGL ES着色语言是一种强类型语言，每个变量和方法使用之前必须定义它，每个变量必须有特定的类型。</p>
<p>OpenGL ES支持的全部数据类型如下表：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>备注                            </th>
</tr>
</thead>
<tbody>
<tr>
<td>void</td>
<td>表示没有返回值或者空的参数</td>
<td></td>
</tr>
<tr>
<td>bool</td>
<td>true或false</td>
<td></td>
</tr>
<tr>
<td>int</td>
<td>有符号整数</td>
<td>提高数组索引循环性能，可以用1十、八、十六进制</td>
</tr>
<tr>
<td>float</td>
<td>单精度浮点型</td>
<td>OpenGL ES不执行类型转换，可以表示一个不含小数部分的float 1.</td>
</tr>
<tr>
<td>vec2</td>
<td>2个分量的浮点型向量</td>
<td></td>
</tr>
<tr>
<td>vec3</td>
<td>3个分量的浮点型向量</td>
<td></td>
</tr>
<tr>
<td>vec4</td>
<td>4个分量的浮点型向量</td>
<td></td>
</tr>
<tr>
<td>ivec2</td>
<td>2个分量的布尔顾类型向量</td>
<td></td>
</tr>
<tr>
<td>ivec3</td>
<td>3个分量的布尔顾类型向量</td>
<td></td>
</tr>
<tr>
<td>ivec4</td>
<td>4个分量的布尔顾类型向量</td>
<td></td>
</tr>
<tr>
<td>mat2</td>
<td>2*2的浮点弄矩阵</td>
<td></td>
</tr>
<tr>
<td>mat3</td>
<td>3*3的浮点弄矩阵</td>
<td></td>
</tr>
<tr>
<td>mat4</td>
<td>4*4的浮点弄矩阵</td>
<td></td>
</tr>
<tr>
<td>sampler2D</td>
<td>表示一个2D纹理句柄</td>
<td></td>
</tr>
<tr>
<td>samplerCube</td>
<td>表示一个立方体纹理句柄</td>
<td></td>
</tr>
</tbody>
</table>
<p>（1）矢量</p>
<p>OpenGL ES中矢量用来表示一具具有2、3、4分量的数据类型，每个分量可以是float、int、bool，其中浮点型的矢量用来表示图形学中一些数据，如颜色、法线、位置、纹理坐标等。</p>
<p>在OpenGL ES中使用矢量，能够充分利用图形硬件的性能处理矢量计算。由硬件实现的矢量计算能够实现并行计算，从而提升应用程序的性能。一些矢量类型的定义如下：</p>
<pre><code>vec2 texcoord1, texcoord2;
vec3 position;
vec4 myRGBA;
ivec2 textureLookup;
bvec3 lessThan;
</code></pre><p>（2）矩阵</p>
<p>矩阵是图形学中又一种有用的数据类型。OpenGL ES着色语言支持2<em>2、3</em>3、4*4的矩阵，矩阵成员只能是浮点型。矩阵的读和写按列优先的顺序排列。矩阵的定义方式如下：</p>
<pre><code>mat2 mat2D;
mat3 optMatrix;
mat4 view, projection;
</code></pre><p>（3）采样器</p>
<p>采样器类型，如（sample2D）用于简化OpenGL ES程序中的纹理处理过程，它通常和OpenGL ES内置纹理查找方法（Teture Lookup）一起工作，用于指定一张纹理。采样器仅可以被定义为方法参数或者使用uniform限定符修饰。</p>
<p>采样器不能用在表达式中，不能作为左值，也不能使用out或者inout的方法参数，这些限制同时作用于自定义的包含采样器成员的结构体。被uniform修饰的采样器变量自动被OpenGL ES初始化，作为方法参数，采样器形参变量只能被同样的采样器变量赋值。</p>
<p>（3）结构体</p>
<p>结构体使用struct关键字，示例如下：</p>
<pre><code>struct light{
    float intensity;
    vec3 position;
}lightVar;
</code></pre><p>light成为新的数据类型，而lightVar是一个light类型的变量。可以使用下面方式声明一个新的变量。</p>
<pre><code>light lightVar2;
</code></pre><p>结构体必有包含至少一个成员声明。成员声明只能包含精度限定符。成员类型必须是已被定义的类型，OpenGL ES着色语言不支持前向引用，也不允许嵌套定义。成员定义不包含任何初始化器，结构体成员变量可以在初始化时使用构造器构造。成员可以是数组，但是数组的长度必须是固定的，或者是一个常量表达式。</p>
<p>（4）数组</p>
<p>相同类型的变量可以组合为一个数组。在OpenGL ES着色语言中，数组相较C语言中有一些限制。数组的尺寸必须声明为一个大于零的常量表达式。当数组作为方法参数时，必须声明数组尺寸。所有基本类型各结构体都可以作为数组类型。OpenGL ES着色语言中只包含一维数组，示例如下：</p>
<pre><code>float frequencies[3];
uniform vec4 lightPosition[4];

const int numLights = 2;
light lights[numLight];
</code></pre><p>在着色器程序中，不能在定义时初始化数组成员。数组的成员只能在定义之逐一赋值。</p>
<h3 id="3-存储限定符"><a href="#3-存储限定符" class="headerlink" title="3 存储限定符"></a>3 存储限定符</h3><p>变量的声明可以使用一个存储限定符来修饰。限定符置于类型前面，OpenGL ES着色语言支持的存储限定符如下表：</p>
<table>
<thead>
<tr>
<th>存储限定符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>&lt; none; default&gt;</td>
<td>局部可读写的变量，或者方法参数</td>
</tr>
<tr>
<td>const</td>
<td>编译时常量，或者表示只读的方法参数</td>
</tr>
<tr>
<td>attribure</td>
<td>由应用程序传输给顶点着色器的顶点数据</td>
</tr>
<tr>
<td>uniform</td>
<td>由应用程序传输给顶点，片段着色器的全局变量，在一个图元绘制期间其值不变</td>
</tr>
<tr>
<td>varying</td>
<td>由顶点着色器传输给片段着色器的，经过插值的易变量</td>
</tr>
</tbody>
</table>
<p>本地变量和方法只能使用const限定符，方法返回值和结构体成员不能使用限定符。</p>
<p>不包含任何限定符或者包含const限定符的全局变量可以包含初始化器，这种情况下这些变量会在main()函数开始之后第一行代码之前被初始化，这些初始化值必须是常量表达式。</p>
<p>没有任何限定符的全局变量如果没有在定义时初始化或者在程序中被初始化，其值在进入mian()函数之后是未定义的。</p>
<p>uniform、attribute、varying限定符修饰的变量不能在初始化时被赋值，这是由OpenGL ES计算提供。</p>
<p>数据不能从一个着色器程序传递给下一个阶段的着色器程序，这样会阻止同一个着色器程序百在多个顶点或者片段中进行并行计算。</p>
<p>（1）默认限定符</p>
<p>如果一个全局变量没有指定限定符，则该变量与应用程序或者其他正在运行的处理单元没有任何关系。不管是全局变量还是本地变量，它们总是在自己的处理单元被分配内存，因此可以对它们执行读和写操作。</p>
<p>（2）常量限定符</p>
<p>const用来修饰一个编译时的常量，常量在自己的处理单元内为只读状态。定义常量可以避免在着色器程序中写入一些奇怪的数字。const可以修饰任何基本数据类型，常量必须在定义时被初始化，在外部对其赋值则会导致错误，示例如下：</p>
<pre><code>const vec3 zAxis = vec3(0.0, 0.0, 1.0);
</code></pre><p>结构体成员不能被声明为常量，但是结构体可以被声明为常量，并且需要在初始化时使用初始化器初始化其值。</p>
<p>常量必须被初始化为一个常量表达式。数组或者包含的数组的结构体不能被声明为常量，因为数组不能在定义时被初始化。</p>
<p>（3）属性限定符</p>
<p>attribute用来定义一些特殊的变量，这些变量可以由应用程序提供，通过OpenGL ES传递给顶点着色器程序。属性限定符只能用在顶点着色器中，在其他任何类型的着色器程序中使用属性限定符会导致编译时错误。</p>
<p>使用属性限定符修饰的变量在顶点着色器程序中是只读的，它的值来自应用程序通过OpenGL ES API或者顶点数组的一部分传递给顶点着色器。其类型只能是float、vec2、vec3、vec4、mat2、mat3、mat4，顶点属性不能被定义为数组或者结构体类型，示例如下：</p>
<pre><code>attribute vec4 position;
attribute vec3 normal;
attribute vec2 texCoord;
</code></pre><p>实际上，除了矩阵类型，每个属性变量被存储为一个由4个分量组成的存储空间，每个变量根据其类型占据其中的1~4个分量。当一个属性值传递给顶点着色器程序时，任何没有填充值的分量将会被OpenGl ES设为默认值：每个存储空间的最后一个分量被填充为1，其他分量则填充为0。如下图：</p>
<p>OpenGL ES2.0要求图形硬件至少提供8个顶点属性存储空间。可以通过glGetIntegerv()方法查询GL_MAX_VERTEX_ATTRIBUTE，其表示当前图形硬件支持的最大属性存储空间数量。</p>
<p>从上可以看出一个float变量和一个vec4变量占据相同的存储空间，因此，可以将一些无关联的变量组合成一个vec4变量来节省存储空间，也可以用来定义更多的属性变量。另外一个存储空间对应一个vec4变量，因此，一个mat4变量将占据4个属性存储空间。</p>
<p>超出图形硬件支持的最大存储空间数量将会导致链接错误，所以，应用程序需要小心处理属性变量的数量。但是，当一个属性变量在顶点着色器程序中被定义却从没有被使用过，则不会在计算内，在编译时会被优化掉。</p>
<p>此外，属性变量必须是全局变量。</p>
<p>（4）全局限定符</p>
<p>uniform用于定义一个全局变量，该变量可以被片元处理阶段的所有着色器使用。通常用全局变量来存储坐标变换矩阵、光照参数或者一些颜色值。全局变量是只读的，它只能被应用程序通过OpenGL ES API设置，或者间接被OpenGL ES设置。示例如下：</p>
<pre><code>uniform vec4 lightPosition;
</code></pre><p>（5）易变量限定符</p>
<h3 id="4-构造器"><a href="#4-构造器" class="headerlink" title="4 构造器"></a>4 构造器</h3><h3 id="5-矢量的分量"><a href="#5-矢量的分量" class="headerlink" title="5 矢量的分量"></a>5 矢量的分量</h3><h3 id="6-矩阵的分量"><a href="#6-矩阵的分量" class="headerlink" title="6 矩阵的分量"></a>6 矩阵的分量</h3><h3 id="7-结构休和成员"><a href="#7-结构休和成员" class="headerlink" title="7 结构休和成员"></a>7 结构休和成员</h3><h3 id="8-矢量和矩阵操作符"><a href="#8-矢量和矩阵操作符" class="headerlink" title="8 矢量和矩阵操作符"></a>8 矢量和矩阵操作符</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/2.1 OpenGL ES着色语言/" data-id="cjov31rhk000a88rivlbi8dqj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/2 OpenGL ES 2.0概览" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/2 OpenGL ES 2.0概览/" class="article-date">
  <time datetime="2018-11-24T03:55:32.928Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/2 OpenGL ES 2.0概览/">OpenGL ES2.0概览</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>游戏引擎对开发者提供了一级UI元素，以及组织这些UI元素构成游戏场景的接口。在游戏引擎内部，则将这些UI元素转化为一系列OpenGL ES命令的调用，并在每一帧将它们绘制到设备屏幕上。因此，了解OpenGL ES，我们能清楚的知道每个UI元素是怎样被绘制的，知道怎样使用它们会三室两厅最高的性能，同时也能更灵活的使用着色器来增强游戏画面的表现力。</p>
<h3 id="1-GPU"><a href="#1-GPU" class="headerlink" title="1 GPU"></a>1 GPU</h3><p>GPU是集成了坐标变换、光照、图元裁剪、渲染的单一处理芯片。</p>
<p>衡量GPU的性能高低量每秒像素填充率，指GPU每秒所渲染的像素数量，例如，苹果A7处理器集成的GPU为Power G6430，它的像素填充率为20.8GP/s。</p>
<p>应用程序通常通过一些图形库来使用GPU处理图形计算，如OpenGL、Direct X等。</p>
<h5 id="1-1-GPU和CPU的区别"><a href="#1-1-GPU和CPU的区别" class="headerlink" title="1.1 GPU和CPU的区别"></a>1.1 GPU和CPU的区别</h5><ul>
<li>CPU量专门为顺序串行处理而优化的几个核心组成，</li>
<li>GPU则由以千计的更小、更高效的核心组成，这些核心专门为并行处理多任务而设计</li>
</ul>
<h3 id="2-什么是OpenGL-ES"><a href="#2-什么是OpenGL-ES" class="headerlink" title="2 什么是OpenGL ES"></a>2 什么是OpenGL ES</h3><p>OpenGL ES是一套图形硬件的软件接口，它直接和GPU进行交互，使我们可以创建实时的3D图形程序。<br>OpenGL ES主要有1.0、2.0、3.0三个版本，大多数移动平台主要使用2.0进行绘制，OpenGL ES2.0版本针对可编程管线成硬件。</p>
<p>OpenGL的全部功能主要集中在怎样将程序中定义的各种2D、3D模型绘制到帧缓存中，或者如何将数据从帧缓存中读取到程序中，如保存一张场景截图。除此之外，OpenGL并不提供其他与硬件相关的功能。</p>
<h3 id="3-OpenGL-ES-2-0-渲染管线"><a href="#3-OpenGL-ES-2-0-渲染管线" class="headerlink" title="3 OpenGL ES 2.0 渲染管线"></a>3 OpenGL ES 2.0 渲染管线</h3><p>OpenGL ES将3D场景绘制到2D屏幕上，这一过程通过一系列的渲染管线完成。OpenGL ES API就是用来向各个阶段提供一些数据各状态指令以使渲染管线能够按照要求正确的将物体绘制在屏幕上。</p>
<p>OpenGL ES的渲染管线如下图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/OpenGL%20ES%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF.png" alt=""></p>
<p>上图中，左边的客户端骑通过调用OpenGL ES接口，将顶点、着色器程序、纹理、其他GL状态参数传入右边的GL服务端，然后在客户端调用绘制命令（如DrawArray），GL会对输入的图元逐一执行渲染管线的每个阶段，然后将每个像素的颜色值写入帧缓冲，最后视窗系统就可以将帧缓冲的颜色值显示在屏幕上了。此外，应用程序也可以从帧缓冲中将数据提取到客户端。</p>
<p>整个管线中，顶点着色器(Vertex Shader)、片段着色器(Fragment Shader)是可编程部分，应用程序可以通过着色器程序达到在GUP中被作用于渲染管线的目的，而在其他阶段则只能使用一些固定的GL命令影响该阶段的执行，下面逐一介绍每个阶段的作用。</p>
<h5 id="3-1-顶点数组"><a href="#3-1-顶点数组" class="headerlink" title="3.1 顶点数组"></a>3.1 顶点数组</h5><p>（1）概念</p>
<p>顶点数组：顶点数组实际上是多个数组，顶点坐标、纹理坐标、法线向量、顶点颜色，顶点的每一个颜色都可以指定一个数组，然后用统一的序号来进行访问。比如序号index3就表示取得颜色数组的第3个元素作为颜色、取得纹理坐标数组的第3个元素作为纹理坐标，取得法线向量数组的第3个元素作为法线向量、取得顶点坐标数组的第三个元素作为顶上坐标…把所有数据综合起来最后得到一个顶点。此外，我们也可以把所有数据放在一个数组，称之为交错数组。</p>
<p>顶点索引：假设我们绘制一个模型，这个模型由无数三角片组成，大部分三角片都是连续拼接，每两个三角形可能有一个或者两个完全相同的顶点（位置、颜色、纹理坐标），这些顶点其实是可以共享的。OpenGL ES为我们指定了一种更加灵活的方式——顶点索引数组，即我们只需要创建好必要的顶点数据，然后用索引去对应每一个对应的顶点数据。</p>
<p>顶点缓冲区对象（VBO）：使用VBO可以将我们的顶点数据存放在图像的内存中，而不需要存放在CPU端的内存中，就不需要在每次绘制时发送大量的数据到GPU端了。</p>
<p>索引缓冲对象（IBO）：和VBO一样，不同的是存储的是索引数组。</p>
<p>顶点数组对象（VAO）: VAO其实就是绑定VBO和IBO的一个包装对象，我们把有关联的VBO和IBO绑定到一个VAO上，我们每瓶只需要使用VAO就可以绘制了。</p>
<p>（2）关于OpenGL ES 3D模型的绘制：</p>
<ul>
<li>OpenGL不提供对3D模型的定义，在传入OpenGL之前，应用程序将3D模型转换为一组图元的集合。</li>
<li>图元是一个点、线段、或者三角形（OpenGL桌面版还包括四边形和多边形）</li>
<li>每个模型是独立绘制的，修改其中一个模型的设置不会影响其他模型。</li>
</ul>
<p>如图，3D模型被转换为一组图元：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/3D%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%9B%BE%E5%85%83.png" alt=""></p>
<p>（3）顶点数组</p>
<p>图元由一个顶点或多个顶点组成，每个顶点定义一个点、一条边的一端或三角形的一个角。每个顶点关联一个数据，数据包括顶点坐标、颜色、法向量、纹理坐标。所有这些顶点相关信息构成顶点数组，这些数据被上传到GL服务端就可以进行绘制了。示例如下：通过顶点缓冲对象绑定顶点数组数据。</p>
<pre><code>void initVertexBufferObjects(vertext_t *vertexBuffer, GLushort *indices, GLunit numIndices, GLunit *vboIds)
{
    glGenBuffers(2, vboIds);
    glBinBuffer(GL_ARRAY_BUFFER, vboIds[0]);
    glBufferData(GL_ARRAY_BUFFER, numberVertices *sizeof(vertex_t), vertexBuffer, GL_STATIC_DRAW)
}
</code></pre><p>上述程序演示了如何通过缓冲对象（Vertex Buffer Objects）绑定顶点数组数据。</p>
<ul>
<li>glGenBuffers()方法分配了指定个数的VBO对象名称，这里分配了两个缓冲对象，一个用来存储顶点数组，另一个用来存储每个顶点的索引值。</li>
<li>glBindBuffer设置当前缓冲对象。</li>
<li>glBufferData则会将数据绑定到当前缓冲对象。</li>
</ul>
<p>这样在开始绘制一个模型之前，我们就将顶点信息传入了OpenGL ES渲染管线。</p>
<p>OpenGL中的命令总是按照它被接受的顺序执行的，这意味着一组图元必须全部绘制完毕才会开始下一组图元，同时也意味着程序对帧缓冲的像素的读取结果一定是该命令之前所有OpenGL命令执行结果。</p>
<h5 id="3-2-顶点着色器"><a href="#3-2-顶点着色器" class="headerlink" title="3.2 顶点着色器"></a>3.2 顶点着色器</h5><p>顶点着色器是一段类似C语言的程序，由程序员提供并在GPU上执行，对每个顶点执行一次运算。</p>
<p>上面顶点数组被传入顶点着色器，顶点着色器使用顶点数据来计算该顶点的坐标、颜色、光照。纹理。在渲染管线中每个顶点都被独立的执行。</p>
<p>顶点着色器的主要功能：</p>
<p>（1）执行顶点坐标变换，输出顶点在裁剪坐标系中坐标变量为gl_Position。应用程序中设置设置图元的坐标通常是本地坐标系，而GL不认识，所以在顶点着色器中要对本地坐标执行模型视图转换，将本地坐标系转为裁剪坐标系。</p>
<p>（2）向后面的片段着色器提供易变（Varying）变量。易变量会在图元装配之后被执行插值计算，如果是单一采样，其插值点为片段的中心，如果是多重采样，其插值点可能为多个采样片段中的任意一个位。易变量可以用来保存插值计算片段的颜色、纹理坐标等信息。</p>
<h5 id="3-3-图元装配"><a href="#3-3-图元装配" class="headerlink" title="3.3 图元装配"></a>3.3 图元装配</h5><p>（1）图元装配的流程</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/1030%E5%9B%BE%E5%85%83%E8%A3%85%E9%85%8D%E5%8F%8A%E5%9D%90%E6%A0%87%E7%B3%BB.png" alt=""></p>
<p>顶点着色器程序输出顶点坐标之后，各个顶点按照绘制命令(DrawArray或者DrawElements)中的图元类型参数及顶点索引数组被组装成一个一个图元。图元装配阶段会对图元按照如上图所示的描述各顺序执行图元操作。</p>
<p>在图元装配阶段，顶点坐标会经过多个坐标系的变换。如上图所示，顶点数组首先通过GL命令输入GL管线中，此时，顶点坐标位于应用程序的本地坐标系；经过顶点着色器计算之后，顶点坐标被转换为裁剪坐标系的坐标（这通常需要传入一个模型视图变换矩阵），裁剪坐标系被定义为一个视锥体；经过视锥体裁剪之后的顶点坐标经透视分离（Perspective Division）投影到屏幕或者视口（viewport）上，称为规则化（Normalized）的设备坐标系，这些坐标值的取值范围为[0, 1]；最后，规则化的坐标（xd, yd, zd）经过视口变换（Viewport Transformation）转换为屏幕坐标。</p>
<p>通过上述这些坐标转换，图元的顶点坐标最终被转换到屏幕坐标上。值得注意的是，在视口变换中，[-1, 1]的值被转换到视口上，所以，视锥体定义的远近平面的比例应该与视口保持一致，否则会导致图元变形。</p>
<p>（2）视锥体裁剪</p>
<p>视锥体是游戏场景中的一个可视空间，裁剪坐标系被定义在了一个视锥体裁剪空间里。由6个裁剪平面组成，分别是近平面、远平面、左平面、右平面、上平面和下平面，处于视锥体以外的图元将会补丢弃。如果图元与视锥体相交，则会发生裁剪，产生新的图元。</p>
<p>透视裁剪是一个比较影响性能的过程，因为每个图元都需要与6个平面进行相交计算并产生新的图元，但是一般在x轴、y轴方向超出屏幕（由glViewprot定义）的部分则无须产生新的图元，这些图元能在视口变换的时候被高效的丢弃。</p>
<p>视锥体在3D中通常表现为一个摄像机，其观察点为裁剪坐标的原点，方向为穿过远近平面的中点。在Cocos2d-x中，Director的setProjection()方法定义了视锥体。如下：</p>
<pre><code>void Director::setProjection(Projection projection)
{
    Size size = _winSizeInpoints;
    setViewport();

    switch(projection)
    {

        case Projection::_2D:
        {
            Mat4 orthoMatrix;
            Mat4::createOrthographicOffCenter(0, size.width, 0, size.height, -1024, 1024, &amp;orthoMatrix);
            loadMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, orthoMatrix);
            loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
            break;
        }

        case Projection::_3D:
        {
            float zeye = this-&gt;getZEye();
            Mat4 matrixPerspcetive, matrixLookup;

            loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION);
            Mat4::createPerspective(60, (GLfloat)size.width/size.height, 10, zeye+size.height/2, &amp;matrixPerspective);
            multiplyMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, matrixLookup);

            Vec3 eye(size.width/2, size.height/2, zeye), center(seize.width/2, size.height/2, 0.0f), up(0.0f, 1,0f, 0.0f);
            Mat4::createLookAt(eye, center, up, &amp;matrixLookup);
            Mat4 proj3d = matrixPerspective * matrixLoopup;

            loadMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_PROJECTION, proj3d);
            loadIdentityMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
        }
    }

    _projection = projection;
    GL::setProjectionMatrixDirty();

    _eventDispatcher-&gt;dispatchEvent(_eventProjectionChanged);
}
</code></pre><p>在setProjection方法中，定义了一个张角为60度、视口比例为屏幕宽高比、近平面距离为10远平面距离为zeye + size.height/2的视锥体；摄像机位于屏幕向后zeye的距离。</p>
<p>在3D应用程序中可以通过修改摄像机的位置和方向，产生不同位置各角度的视锥体，以达到移到报仇机的效果。</p>
<h5 id="3-4-光栅化"><a href="#3-4-光栅化" class="headerlink" title="3.4 光栅化"></a>3.4 光栅化</h5><p>通过图元装配，所有3D图元已经转换为屏幕上的2D图元。光栅化的主要作用是将2D图元转换为一系列的片段，并计算每个片段的位置。将几何数据经过一系列变换后最终转换为像素，从而呈现在显示设备上的过程，如图所示：</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0822%E5%85%89%E6%A0%85%E5%8C%96.jpg" alt=""></p>
<p>每个片段会执行一次片段着色器程序，在片段着色器中使用光栅化计算出的片段位置给每个片段着色，各个片段执行器的执行仍然量并行的。</p>
<p>在光栅化之前，要判断图元是面向观察者还是背向观察者，以决定是否需要丢弃图元。可以通过getForntFace来决定那个方向为正，并通过glCullFace命令来决定需要保留哪一面。这样做可以减少一些不必要的绘制，即GPU的浪费。</p>
<p>光栅化的过程主要是对图元中的片段进行采样，以决定哪些片段位于图元之内。在这个过程中，因为这些片段的坐标值为离散的整数，所以会导致精度损失，如上图边沿产生的锯齿。而光栅化会使用各种算法来保证每个片段位置尽可能准确。</p>
<p>在计算每个位置片段坐标之后，片段着色器就能使用这个坐标值对该片段进行着色了，这个片段为为最终屏幕上的一个像素点。此外，光栅化还需要计算那些在顶点着色器中定义的易变量的插值，这些值最终被用在片段着色器中，以计算片段最终的颜色值，如片段的纹理坐标、颜色等。</p>
<h5 id="3-5-片段着色器"><a href="#3-5-片段着色器" class="headerlink" title="3.5 片段着色器"></a>3.5 片段着色器</h5><p>可编程的片段着色器是实现一些高级特效（如纹理贴图、光照、环境光、阴影等功能）的基础，片段着色器的功能主要是计算每个片段的颜色值（或者丢弃该片段）。</p>
<p>在片段着色器出现之前，渲染管线都只是在和顶点、图元交互。在3D图形程序开发中，贴图是最重要的部分，程序可以通过GL命令将纹理数据上传至GL内存中，这些纹理可以被片段着色器使用。示例如下：</p>
<pre><code>GLuint textureId;
glGenTextures(1, &amp;textureId);
glBindTexture(GL_TEXTURE_2D, textureId);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 2, 2, 2, 0, GL_RGB, GL_UNSIGNED_BYTE, pixels);
</code></pre><p>与绑定顶点类似，该程序首先通过glGenTextres产生一个纹理对象名称，然后通过glBindTexture()方法绑定当前纹理，之后，glTexImage2D()将内存中的图像上传至OpenGL ES服务器。</p>
<p>片段着色器根据顶点着色器输入的顶点纹理坐标对纹理进行采样，以计算该片段的颜色值，这些值最后被写入帧缓冲。由于在实际贴图过程中可能被放大或者缩小，以及纹理坐标超出(0, 0)和(1, 1)之间的问题。为了处理这些问题，一般在绑定纹理坐标的时候可能通过glTexParameter()方法来设置纹理相关的一些处理模式，例如多级纹理。</p>
<p>另外，片段着色器也是执行光照等高级特效的地方。例如传给片段着色器一个光源位置和光源颜色，根据一定的公式计算出一个新颜色值，这样就可以实际光照特效了。</p>
<h5 id="3-6-片段测试"><a href="#3-6-片段测试" class="headerlink" title="3.6 片段测试"></a>3.6 片段测试</h5><p>片段着色器输出的颜色值还要经过几个阶段的片段操作。这些操作可能会修改片段的颜色值或者丢弃该片段，最终的片段颜色值会被写入帧缓冲区，这些步骤包括像素所有权测试、裁剪测试、模板测试、深度测试、混合、抖动等。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0823%E7%89%87%E6%AE%B5%E6%93%8D%E4%BD%9C.JPG" alt=""></p>
<ul>
<li>像素所有权测试用来判断帧缓冲区中该位置的像素是否属于当前OpenGL ES。例如，在窗口系统中该位置可能会被其他应用程序窗口遮挡，此时该像素则不会显示。</li>
<li>glScissor用于设定一个矩形区域，以执行裁剪测试，处于该区域之外的片段会被丢弃。</li>
<li>混合用来描述当前图像怎样与场景中当前位置的颜色值进行组合。</li>
<li>在完成片段测试之后，要么丢弃片段，要么将每个片段对应的颜色、深度、模板值写入帧缓冲区，最终呈现在设备的屏幕上。帧缓冲区中的颜色值可以被读到客户端应用程序中，这样可以实现绘制到纹理效果。</li>
</ul>
<h3 id="4-渲染管线中的并行计算"><a href="#4-渲染管线中的并行计算" class="headerlink" title="4 渲染管线中的并行计算"></a>4 渲染管线中的并行计算</h3><p>GPU是具备高度并行的处理器，OpenGL ES渲染管线中的并行性又是怎样的？</p>
<p>OpenGL ES总是按顺序执行命令，这意味着一个物体必须全部绘制完成才会开始绘制下一个物体，这样能保证在任何情况下，屏幕上显示的都是正确的图像。然而，在每一个管道的各个阶段，所有处理都是并行的，这样做保证了实时显示的性能。</p>
<p>这里的并行有两个方面：一方面是纵向并行，是指在每个阶段内部被拆分成多个子任务，这些子任务像工厂里的流水线一样并行处理；另一方面是横向并行，即多个顶点、多个图元、多个图元都是独立并行处理的，这很大提高了渲染的性能。</p>
<p>也正是因为每个顶点、图元及片段被并行处理，所以它们没有任何状态。例如，在顶点着色器程序中，我们不知道下一个要处理的顶点是什么，所有顶点着色器各片段着色器中的变量都必须通过程序获取，或者通过光栅化阶段的插值计算。</p>
<p>OpenGL ES是一个状态机，管道中的很多操作需要依赖当前特定的状态值，如是否执行深度测试，这些状态会影响管道中的所有顶点、图示、片段的执行。这样做能保证并行计算，从而实现更高的绘制。</p>
<h3 id="5-构建高性能的渲染引擎"><a href="#5-构建高性能的渲染引擎" class="headerlink" title="5 构建高性能的渲染引擎"></a>5 构建高性能的渲染引擎</h3><p>游戏是对渲染的实时性要求很高，为了达到更好的显示效果，每帧需要渲染的物体数量和纹理纹理精细度都很大的增加。所以即使OpenGL ES有很高的渲染性能，游戏引擎仍然需要采用一些更好和处理方式来使游戏引擎性能最大化，这是主要分析以下方面。</p>
<p>（1）减少渲染次数</p>
<p>通过前面我们知道，多个绘制之间是顺序执行的，减少命令的调用（其实现方式是将更多的顶点包装到一个顶点数组中）。实际上是在每个时刻让GPU做了更多事情（同一管道内的顶点并行执行）。同时，每个渲染命令都伴随着顶点、纹理数据从客户端复制到客户端的，减少渲染命令调用次数，就减少了这种数据的传输。Cocos2d-x在这方面的处理方式是使用自动批绘制，将相邻的针对同一绘制参数的命令合并在一起进行绘制，以及使用自动裁剪功能删除屏幕之外的元素。</p>
<p>（2）将渲染从主线程中分离</p>
<p>这样不仅能充分使用现代CPU多处理器、多线程的优势，使CPU有更多的时间处理游戏逻辑，还能避免CPU各GPU之间处理速度的差异导致对渲染性能的影响。同时，统一处理所有绘制命令还可以集中进行一些优化。例如，可以将相邻且使用同一纹理的绘制命令合并到一起，减少DrawCall的次数。遗憾的是，Cocos2d-x3.0仍然是一个单线程引擎，但是它已经将绘制逻辑从UI树中抽离，使绘制逻辑更灵活，易于扩展维护。</p>
<h3 id="6-帧缓冲"><a href="#6-帧缓冲" class="headerlink" title="6 帧缓冲"></a>6 帧缓冲</h3><p>OpenGL ES渲染管道最终目的是将每个像素点的颜色、深度、模板等数据输送到帧缓冲（FrameBuffer）区。</p>
<p>帧缓冲区存储着OpenGL ES绘制的每个像素点的所有最终信息，包括颜色、深度和模板值。一个帧缓冲上有三个对应的附加点，它们组成了一个逻辑缓冲区，分别用来存储所有像素的颜色、深度和模板数据。每个附加点可以绑定到一个渲染缓冲对象（Renderbuffer Objects）上，其中颜色和深度附加点还可以绑定到一个纹理上，这样就可以实现绘制到纹理，而不是显示设备了。</p>
<p>帧缓冲区通常由视窗系统提供，也可以通过应用程序创建。应用程序可以将不同的内容绘制到不同的帧缓冲中。在多个帧缓冲之间切换不需要切换OpenGL ES的上下文，通常可以使用此方式来高效地将内容绘制到纹理。（参考RenderTexture类）</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0823%E5%B8%A7%E7%BC%93%E5%86%B2.JPG" alt=""></p>
<p>只有将内容绘制到视窗提供的帧缓冲中，才能将内容输出到显示设备上，视图系统提供的帧缓冲的颜色缓冲区通常由两个缓冲对象组成，分别是一个前端缓冲和一个后端缓冲。OpenGL ES将所有内容首先绘制到后端缓冲区，然后在每一帧绘制完成之后一次性通过交换前后缓冲区将内容显示在屏幕上。之后，前端缓冲变为后端缓冲，后后端缓冲变为前端缓冲。之所以设计成双端缓冲，是因为直接绘制到设备屏幕，用户会看到一个完整的场景中的物体被一个一个绘制出来的过程，这种体验非常糟糕。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/2 OpenGL ES 2.0概览/" data-id="cjov31rhi000988rilevq1t8j" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/1. Cocos2d-x3.0的新特性" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/1. Cocos2d-x3.0的新特性/" class="article-date">
  <time datetime="2018-11-24T03:55:32.923Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++-P/1. Cocos2d-x3.0的新特性/">Cocos2d-x3.0的新特性</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Cocos2d-x3-0的新特性"><a href="#Cocos2d-x3-0的新特性" class="headerlink" title="Cocos2d-x3.0的新特性"></a>Cocos2d-x3.0的新特性</h1><h3 id="1-使用C-风格"><a href="#1-使用C-风格" class="headerlink" title="1. 使用C++风格"></a>1. 使用C++风格</h3><h5 id="1-1使用命名空间代替“CC”前缀"><a href="#1-1使用命名空间代替“CC”前缀" class="headerlink" title="1.1使用命名空间代替“CC”前缀"></a>1.1使用命名空间代替“CC”前缀</h5><p>例如：CCSprite更名为Sprite;一些全局方法也被加入相应的命名空间中，如与绘制几何基元相关的方法被加入DrawPrimitives命名空间，与OpenGL ES相关的命令封装则使用GL命名空间。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0319Cocos2d-3.x%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4.png" alt=""></p>
<h5 id="1-2使用clone-代替copy-方法"><a href="#1-2使用clone-代替copy-方法" class="headerlink" title="1.2使用clone()代替copy()方法"></a>1.2使用clone()代替copy()方法</h5><p>clone()方法用来深度复制一个对象。例如Cocos2d-x中的Action广泛使用clone()方法来避免对原对象的修改。也可以利用一些模板对象来动态构造新的对象，以达到类似反射效果。</p>
<p>与之前copy方法不同的是，对于Cocos2d-x系统提供的可复制的对象，clone()方法直接返回一个加入自动回收池的对象，调用者不再需要手动将其加入自动回收池。这也减少了类型转换（为了调用autorelease方法，需要将其转换为Ref或者其子类的类型）所花费的时间。</p>
<pre><code>// v2.1
CCMoveBy *action = (CCMoveBy *)mobe-&gt;copy();
acton-&gt;autorelease;

// v3.0
auto action = move-&gt;clone();
</code></pre><h5 id="1-3用getInstance-和destroyInstance-代替sharedXXX-和endXXX-来使用单例。"><a href="#1-3用getInstance-和destroyInstance-代替sharedXXX-和endXXX-来使用单例。" class="headerlink" title="1.3用getInstance()和destroyInstance()代替sharedXXX()和endXXX()来使用单例。"></a>1.3用getInstance()和destroyInstance()代替sharedXXX()和endXXX()来使用单例。</h5><p>需要注意的是：3.0中TextureCache、Dispatcher等对象不再是全局的单例，它们属于Director,需要通过Director来获取其单例，这使得3.0中可以支持多个窗口，即多个Dirctor。</p>
<h5 id="1-4更明确的get前缀来表示属性获取方法"><a href="#1-4更明确的get前缀来表示属性获取方法" class="headerlink" title="1.4更明确的get前缀来表示属性获取方法"></a>1.4更明确的get前缀来表示属性获取方法</h5><p>在使用get前缀来表示属性获取方法的同时，所有属性获取方法使用const声明来限制其对自身属性的修改。</p>
<pre><code>// v2.0
virtual float getScale();

// v3.0
virtual float getScale() const;
</code></pre><h5 id="1-5对于POD类型使用引用参数代替指针传递"><a href="#1-5对于POD类型使用引用参数代替指针传递" class="headerlink" title="1.5对于POD类型使用引用参数代替指针传递"></a>1.5对于POD类型使用引用参数代替指针传递</h5><p>包括TexParams、Point、Size等，这些对象被分配到栈中，更易于内存管理。</p>
<pre><code>// v2.0
void setTexParameters(ccTexParams* texParams);

// v3.0
void setTexParameters(const ccTexParams&amp; texParams);
</code></pre><h5 id="1-6部分C-11的特性"><a href="#1-6部分C-11的特性" class="headerlink" title="1.6部分C++11的特性"></a>1.6部分C++11的特性</h5><p>3.0中使用了部分C++11的新特性，主要包括std::function、强类型枚举、std::thread、override和final关键字、移动语义。</p>
<p>1）std::function</p>
<p>std::function可以被传递一个lambda表达式，亦可以通过std::bind表达式绑定一个方法指针，这极大提升了可阅读性和灵活性，lambda表达式还可以使用当前作用域的变量。例如：</p>
<pre><code>CallFunc::create([&amp;](){
    auto sprite = Sprite::create(&quot;sp.png&quot;);
    this-&gt;addChild(sprite);
});
</code></pre><p>2)强类型枚举</p>
<p>v2.0用k前缀来表示枚举和常量。由于这些参数可以被int型变量替换，往往会造成一些难以察觉的错误。所以v3.0使用强类型来避免这种情况。</p>
<p><img src="http://7xqzxs.com1.z0.glb.clouddn.com/0320coco2d-x3.x%E4%BD%BF%E7%94%A8%E5%BC%BA%E7%B1%BB%E5%9E%8B%E6%9E%9A%E4%B8%BE.png" alt=""></p>
<p>3) override</p>
<p>override用来在编译时检测一些可能的重载错误。当一个方法声明为override关键字时，必须能在其父类中找到相应的可重载方法，否则编译器将产生错误。</p>
<pre><code>class Sprite : public Node{
    bool isFlipY(void) const;
    void setFlipY(bool bFlipY)

    // override
    virtual void setTexture(Texture2D* texture) override;
    virtual Texture2D* getTexture() const override;

    inline void setBlendFunc(const BlendFunc &amp;blendFunc) override;
    inline const BlendFunc&amp; getBlendFunc() const override;
}
</code></pre><p>4) std::thread的使用请见后面章节</p>
<h3 id="2-跨平台的Label"><a href="#2-跨平台的Label" class="headerlink" title="2.跨平台的Label"></a>2.跨平台的Label</h3><p>OpenGL ES并不直接提供对文字的支持，因此游戏中一般需要绘制纹理来显示字体。</p>
<p>cocos2d-x2.x通过向每个平台索要一张完整的一段文字的纹理，然后直接绘制该张纹理，这使得每个字体缺乏足够的描述信息。没有各种文字效果（如描边、加粗特效），另外每段不同文字都会生成一张纹理，这也使得文字的绘制性变得很差。</p>
<p>coco2d-x3.x对字体进行了重构：</p>
<p>1）使用了开源的FreeType字体库来解析文字。FreeType生成一段文字对应的纹理，还会返回该纹理中每个字形的定义，如在纹理中的ID、位置、组合间距等字形信息。这位不仅能通过着色器程序给每个文字添加不同的特效，不能让多个文字共享一张纹理。</p>
<p>2）改善了字体的接口，使LabelTTF、LabelBMFont、Label拥有相同的属性及方法。它们唯一的区别只有通过不同的方式生成和加载纹理。</p>
<h3 id="3-新渲染系统"><a href="#3-新渲染系统" class="headerlink" title="3.新渲染系统"></a>3.新渲染系统</h3><p>单独说明</p>
<h3 id="4-统一的消息分发"><a href="#4-统一的消息分发" class="headerlink" title="4.统一的消息分发"></a>4.统一的消息分发</h3><p>Coco2d-x3.x将之前的CCTouchDIspatcher、CCKeypadDispather、CCKeyboardDispatcher及CCAccelerometerDispatcher封装成一个统一的事件分发器——EventDispatcher。</p>
<p>新事件分发器不仅可以处理系统提供的事件，还可以向Dispatche注册自定义事件。用它来分发游戏中的自定义事件。</p>
<p>在2.x中的CCTouchDispatcher使用一个int类型的数字来表示触摸事件处理的优先级，使得开发者不得不小心设置各个地方处理触摸事件的优先级。大多数时候使用场景层级相对应的关系来表示处理触摸事件的优先级。</p>
<p>在3.0中，仍然保留一个数字作为事件指定优先级的机制，但是新增加了一种指定优先级的方式，可以将一个事件关联到一个UI元素，而这个类型的事件将根据该元素在场景中的位置被分发，离屏幕最近的订阅者优先处理这个事件。</p>
<p>EventDispatche会元素的绘制顺序计算一个优先级，以保证事件分发器按正确的UI顺序分发事件，示例如下：</p>
<pre><code>void addEventListenerWithSceneGraphPriority(EventListener* listener, Node* node);

void addEventListenerWIthFixedPriority(EventListener* listener, int fixedPriority);
</code></pre><h3 id="5-物理引擎集成"><a href="#5-物理引擎集成" class="headerlink" title="5.物理引擎集成"></a>5.物理引擎集成</h3><p>在2.x中，引擎仅提供一个简单的CCPhysicSprite来与一个物理刚体相关联，CCPhysicSprite仅处理精灵和刚体之间的位置变化，其他物理元素，如PhysicsWorld、PhysicShape、PhysicsJoint等，需要开发者直接和物理引擎交互。</p>
<p>在3.x中简化了物理引擎的使用方式，对大部分物理属性及对象进行了封装，主要如下几个方面：</p>
<p>1）.物理世界（Physic World）被集成到Scene中，当创建一个场景的时候可以选择是否创建一个物理世界。为了使用与物理相关的属性，需要开启CC_USE_PHYSICS。</p>
<p>2）.Node元素中包含一个physicsBody属性，可以对任何Node元素及其子类元素设置物理刚体，任何包含physicsBody的Node元素在被添加到场景中时，将被自动加入当前Scene及其他物理参数。</p>
<p>3）.物理刚体包含了大多数 物理属性，如PhysicsShape、PhysicsContact、PhysicsJoint及其他物理参数。</p>
<p>4).可以通过前面提到的统一的事件分发器来接受刚体之间的碰撞事体，前提是只需要注册一个EventListenerPhysicsContact类型的订阅者。</p>
<h3 id="6-新的数据结构"><a href="#6-新的数据结构" class="headerlink" title="6.新的数据结构"></a>6.新的数据结构</h3><p>3.x用Vector<t>和Map&lt;K, V&gt;代替CCArray和CCDictionary，新的容器使用模板类来避免不必要的类型转换，同时能够完美支持标准标准库中各种迭代操作，如std:find()、std::sort()。</t></p>
<p>实际上在Cocos2d-x3.0中，Vector<t>和Map&lt;K, T&gt;是对C++标准库中std::vector<t>和std::unorderd_map&lt;K,T&gt;的封装，使其能够结合Cocos2d-x的内存管理方式。</t></t></p>
<p>1).Map&lt;K, V&gt;的性能</p>
<p>对于Map&lt;K, V&gt;，Cocos2d-X默认使用std::unordered_map将每个Key值转化为Hash值存储，并将其按照Hash值排序，所以它不符合实际字典中的key值或者value值的存储顺序。unordered_map对于单个Key值的查找有更快的速度，只需要将Key值转换为Hash值，然后做一次或多次相等比较，复杂度为O(n)。而std::map的find复杂度为O(log2(n))，它在每个元素之间使用小于比较。</p>
<p>std::unordered_map初始化的时候分配一定数量（通常很少）的buckets来存储Key/Value对，每个bucket对应一个Hash值，Hash值是buckets的数量计算的，所以当新增元素的时候，一个bucket可能会对应多个Hash值，这会照成冲突，此时std::unordered_map就需要重新计算所有hash值，而这会造成冲突，此时std::unorderde_map就需要重新计算所有hash值，而这会造成一定的性能问题。所以需要在短时间内插入一定数量的数据，最好使用resverse()方法来设定bucket的数量，以减少不必要的rehash计算，如果只是偶尔插入或删除数据，则没有必要，因为resverve()方法会增加unorderd_map的内存占用。</p>
<p>另外一个注意的地方是std::hash<t>的计算。std::unordered_map使用特殊的Hash算法，当其类型为整数时，直接将其自身作为Hash值，从而避免了Hash值的计算。所以，尽量使用整型作为Map&lt;K, V&gt;的Key类型。</t></p>
<p>2).与Cocos2d-x内存管理的结合</p>
<p>在cocos2d-x的使用场景中，CCArray和CCDictionary通常被分配在堆上，因此需要丰适当的地方释放其内存。</p>
<p>新的容器不再继承自Ref，通常应该将其分配到栈上使用，应该注重容器中的元素的内存管理。</p>
<p>Vector<t>和Map&lt;K, V&gt;中的V必须是Ref类型。</t></p>
<pre><code>templete&lt;class K, class V&gt;
class CC_DLL Map
{
public:
    // Default constructor
    Map&lt;K, V&gt;()
    : _data()
    {
        // static_assert，C++11的静态断言来实现编译时的类型检查，static_asset和asset类似，可以接受一个条件表达式，检查其结果是满足条件。static_assert是在编译时执行，assert是在运行时执行
        // 检查其模板中V是否为Ref类型
        static_assert(std::is_convertible&lt;V, Ref*&gt;::value, &quot;Invalid Type for cocos2d::Map&lt;K, V&gt;&quot;);

        CCLOGINFO(&quot;In the default construction of Map&quot;);
    }
}
</code></pre><p>对V的内存管理实际为：</p>
<blockquote>
<p>以任何形式加入容器中的左值都会执行retain操作使引用计数加1。</p>
</blockquote>
<blockquote>
<p>以Vector<t>为例，拷贝构造函数、赋值操作、pushBack()、replace()、insert()方法都会执行retain操作。</t></p>
</blockquote>
<p>–</p>
<blockquote>
<p>以任何形式从容器中移除的左值都会被执行release操作使引用计数减少1，如析构函数erase、popBack、replace、clear等。</p>
</blockquote>
<pre><code>// 示例
class MyClass : public Ref{
};

void testVector()
{
    auto c1 = new MyClass();
    c1-&gt;autorelease();
    auto c2 = new MyClass();
    c2-&gt;autorelease();

    CCLog(&quot;reference coun1 c1:%d c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    Vector&lt;MyClass*&gt; v1;
    v1.pushBack(c1);
    v1.insert(1, c2);

    CCLog(&quot;reference coun1 c1:%d c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    v1.popBack();
    CCLog(&quot;reference coun1 c1:%d c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    Vector&lt;MyClass *&gt; v2 = Vector&lt;MyClass *&gt;(v1);
    CCLog(&quot;reference coun1 c1:%d c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    Vector&lt;MyClass *&gt; v3 = v1;
    CCLog(&quot;reference coun1 c1:%d c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());
}

// 输出结果
cocos2d: reference count c1:1 c2:1
cocos2d: reference count c1:2 c2:2
cocos2d: reference count c1:2 c2:1
cocos2d: reference count c1:3 c2:1
cocos2d: reference count c1:4 c2:1
</code></pre><p>下标操作符地“[]”会返回一个左值“T&amp;”，在同一语句中对容器元素造成的影响是不可估计的。例如:v[3]-&gt;release()，将会影响容器中元素的内存管理，所以Cocos2d中容器没有提供下标操作，应该用at()方法来返回一个右值。</p>
<pre><code>templete&lt;class T&gt;
class CC_DLL Vector
{
public:
    // Returns the element at position ‘index’ in the vector

    T at(ssize_t index) const
    {
        CCASERT(index &gt;= 0 &amp;&amp; index &lt; size(), &quot;index out of range in getObjectAtIndex()&quot;);
        return _data[index];
    }
}
</code></pre><p>3).移动语义</p>
<p>新的容器类对右值使用了C++11新的移动(std::move)语义，它们实现了移动拷贝函数和移动赋值操作符。从而在使用右值时减少了一些不必要的临时变量的生成和复制。</p>
<pre><code>template&lt;class T&gt;
class CC_DLL Vector
{
public:
    /* Move constructor */
    Vector&lt;T&gt;(Vector&lt;T&gt;&amp;&amp; other)
    {
        static_assert(std::is_convertible&lt;T, Ref*&gt;::value, &quot;Invalid Type for cocos2d::Vector&lt;T&gt;!&quot;)

        CCLOGINFO(&quot;In the move constructor of Vector&quot;);

        _data = std::move(other._data);
    }

    /* Move assignment operator */
    Vector&lt;T&gt;&amp; operator = (Vector&lt;T&gt;&amp;&amp; other)
    {
        if (this != &amp;other)
        {
            CCLOGININFO(&quot;In the move assignment operator&quot;);
            clear();
            _data = std::move(other._data);
        }
        return *this;
    }
}
</code></pre><p>使用如下语句：</p>
<pre><code>Vector&lt;MyClass*&gt; getVector()
{
    auto c1 = new MyClass();
    c1-&gt;autorelease();

    auto c2 = new MyClass();
    c2-&gt;autorelease();

    Vector&lt;MyClass*&gt; v1;
    v1.pushBack(c1);
    v1.insert(0, c2);

    CCLOG(&quot;reference count c1:%d &amp; c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    return v1;
}

void testVectorMove()
{
    Vector&lt;MyClass*&gt; v2 = Vecto&lt;MyClass *&gt;(getVector());
    CCLOG(&quot;reference count c1:%d &amp; c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());

    Vector&lt;MyClass*&gt; v3 = getVector();
    CCLOG(&quot;reference count c1:%d &amp; c2:%d&quot;, c1-&gt;getReferenceCount(), c2-&gt;getReferenceCount());
}

结果：
cocos2d::reference count c1:2 &amp; c2:2
cocos2d::reference count c1:2 &amp; c2:2
cocos2d::reference count c1:2 &amp; c2:2
cocos2d::reference count c1:2 &amp; c2:2
</code></pre><h3 id="7-其他"><a href="#7-其他" class="headerlink" title="7.其他"></a>7.其他</h3><p>1).Console模块用于更方便地进行远程调试，开发者可以通过TCP:5678端口向游戏发送一些命令。</p>
<p>2).3.0提供了很多官方的GUI控件和容器:UIButton、UIListView、UIRichText、UIScrollView、UISlider等。</p>
<p>3).改善了单例的使用，以支持多屏游戏的开发。TextureCache等单例不再通过全局创建，而是通过Director获取。在一个应用程序中可以创建多个Director，这个就可以创建多窗口管理应用程序了。</p>
<p>4).支持3D坐标转换，支持ARM64架构。</p>
<h3 id="补充："><a href="#补充：" class="headerlink" title="补充："></a>补充：</h3><p>#####1.C++ 左值和右值</p>
<p>1.左值和右值的定义</p>
<p>C++中可以放到赋值操作符左边的是左值，可以放到赋值操作符右边的是右值。</p>
<p>有些变量即可以当作左值，又可以当作右值。</p>
<p>2.左值和右值的理解</p>
<p>左值的声明符号为&amp;，右值的符号为&amp;&amp;。</p>
<p>C++中临时对象不能作为左值，但是可以作为常量引用。</p>
<p>#####2.C++移动</p>
<p>有时候我们希望把左值当作右值来用，例如一个变量的值，不再使用了，希望把它的值转移出去，C++中的std::move就是为我们提供了将左值引用 转为右值引用的方法。</p>
<pre><code>// 左值
void print_value(int&amp; i)
{
    std::cout&lt;&lt;&quot;Lvalue&quot; &lt;&lt; i &lt;&lt; std::endl;
}

// 右值
void print_value(int&amp;&amp; i)
{
    std::cout &lt;&lt; &quot;Rvalue&quot; &lt;&lt; i std::endl;
}

int main()
{
    int i = 10;
    print_value(i);
    print_value(std::move(1));
    return 0;
}

// 最常用的交换函数
void swap(T&amp; a, T&amp; b)
{
    T tmp = std::move(a);
    a = std::move(b);
    b = std::move(tmp);
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/1. Cocos2d-x3.0的新特性/" data-id="cjov31rhe000688ri64fx24ir" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++-P/3.3 帧缓冲" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++-P/3.3 帧缓冲/" class="article-date">
  <time datetime="2018-11-24T03:55:32.640Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++-P/3.3 帧缓冲/" data-id="cjov31rgq000388ricqv6qtdm" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Cocos-C++/11 粒子系统" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/Cocos-C++/11 粒子系统/" class="article-date">
  <time datetime="2018-11-24T03:37:30.733Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Cocos2d-C/">Cocos2d-C++</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/Cocos-C++/11 粒子系统/">11 粒子系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="粒子系统"><a href="#粒子系统" class="headerlink" title="粒子系统"></a>粒子系统</h1><h3 id="1-粒子系统"><a href="#1-粒子系统" class="headerlink" title="1.粒子系统"></a>1.粒子系统</h3><p>粒子系统中的组成类（继承关系）：</p>
<p>CCParticleSystem是粒子系统的主要类，它继承自CCNode类，同时实现了TextureProtocol纹理协议。</p>
<p>1).因为粒子系统继承了CCNode类和TextureProtocol协议，说明粒子系统对象可以被添加到引擎画面层次中去，并且必然会包含一张纹理图片用于显示。</p>
<p>2).类ParticleSystem所派生的子类ParticleSystemQuad类，只是在原本粒子系统基础上添加了一些新的属性，为开发者提供了更多的可选属性。此外，ParticleSystemQuad的适用性要好一些，在iOS设备上都能够保持不俗的的性能。</p>
<p>3).ParticleSystemQuad与ParticleSystem主要改变了如下几点：</p>
<ul>
<li>粒子尺寸支持浮点类型。</li>
<li>粒子支持缩放的功能。</li>
<li>粒子支持旋转的功能。</li>
<li>iOS三代的设备之后，它的效率远远超过了ParticalSystem类。</li>
<li>使用更小的内存和显存。</li>
<li>支持矩形的方式。</li>
<li>支持绘制集合的方式。</li>
</ul>
<p>4).粒子特效类,它们都是ParticleSystemQuad的直接子类。</p>
<ul>
<li>ParticleExplosion</li>
<li>ParticleFire</li>
<li>ParticleFireworks</li>
<li>PatticleFlower</li>
<li>ParticleGalaxy</li>
<li>ParticleMeteor</li>
<li>ParticleRain</li>
<li>ParticleSmoke</li>
<li>ParticleSmoke</li>
<li>ParticleSnow</li>
<li>ParticleSpiral</li>
<li>ParticleSun</li>
</ul>
<h3 id="2-粒子的生命周期"><a href="#2-粒子的生命周期" class="headerlink" title="2.粒子的生命周期"></a>2.粒子的生命周期</h3><p>粒子作为一个对象，存在于引擎当中。它一旦诞生都要经历一个完整的生命周期，该生命周期包含了三个阶段：出生、成长、死亡。</p>
<p>1).粒子的出生：引擎中存在一个粒子池，用于存放等待复活的粒子。发射器会从粒子池中获取一个粒子，然后计算赋予初始化属性后，将粒子发射出去。</p>
<p>2).粒子的成长：将粒子发射出去之后，衰减器会在粒子运动过程中不断的刷新，来修正它的属性。这个过程是粒子的成长岁月。</p>
<p>3).在粒子衰减到最后，它就会进入死枉状态。会被放入粒子池中，等待重新被激活。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/24/Cocos-C++/11 粒子系统/" data-id="cjov31riy002588ri5diyyf6e" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cocos-C/">Cocos-C++</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cocos2d-C/">Cocos2d-C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cocos2d-Lua/">Cocos2d-Lua</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cocos2d与OpenGL-ES/">Cocos2d与OpenGL ES</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cococs2d与OpenGL-ES/">Cococs2d与OpenGL ES</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cocos-C/">Cocos-C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cocos-Lua/">Cocos-Lua</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lua/">Lua</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Cococs2d与OpenGL-ES/" style="font-size: 12.5px;">Cococs2d与OpenGL ES</a> <a href="/tags/Cocos-C/" style="font-size: 20px;">Cocos-C++</a> <a href="/tags/Cocos-Lua/" style="font-size: 17.5px;">Cocos-Lua</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/Lua/" style="font-size: 15px;">Lua</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/24/Cocos-C++-P/3.2 精灵/">3.2 精灵</a>
          </li>
        
          <li>
            <a href="/2018/11/24/Cocos-C++-P/3.1（2） 纹理压缩及应用/">3.1(2) 纹理压缩及应用</a>
          </li>
        
          <li>
            <a href="/2018/11/24/Cocos-C++-P/3.1（1） 纹理/">3.1 纹理</a>
          </li>
        
          <li>
            <a href="/2018/11/24/Cocos-C++-P/3 全新的绘制系统/">全新的绘制系统</a>
          </li>
        
          <li>
            <a href="/2018/11/24/Cocos-C++-P/2.2 OpenGL ES 着色程序/">OpenGL ES着色程序</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Zenos<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>